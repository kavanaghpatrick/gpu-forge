"""
{{KERNEL_NAME}} â€” Custom Metal kernel via MLX
Generated by gpu-forge

Uses mx.fast.metal_kernel() to JIT-compile and dispatch a custom
Metal compute kernel on Apple Silicon GPU.
"""

import mlx.core as mx
import time

# ---------------------------------------------------------------------------
# Metal Kernel Source (MSL)
# ---------------------------------------------------------------------------

KERNEL_SOURCE = """
#include <metal_stdlib>
using namespace metal;

[[kernel]] void {{KERNEL_NAME}}(
    device const {{TYPE}}* input  [[buffer(0)]],
    device {{TYPE}}*       output [[buffer(1)]],
    uint tid [[thread_position_in_grid]]
) {
    // TODO: Replace with your compute logic
    output[tid] = input[tid];
}
"""

# ---------------------------------------------------------------------------
# Create MLX Custom Kernel
# ---------------------------------------------------------------------------

# IMPORTANT: Cache the kernel object to avoid recompilation overhead.
# mx.fast.metal_kernel() JIT-compiles a new Metal library each call.
_kernel = mx.fast.metal_kernel(
    name="{{KERNEL_NAME}}",
    source=KERNEL_SOURCE,
    input_names=["input"],
    output_names=["output"],
)

# ---------------------------------------------------------------------------
# Kernel Dispatch
# ---------------------------------------------------------------------------


def run_kernel(input_array: mx.array) -> mx.array:
    """Dispatch {{KERNEL_NAME}} on the GPU.

    Args:
        input_array: Input data (will be cast to {{TYPE}} if needed).

    Returns:
        Output array with same shape as input.
    """
    n = input_array.size

    # Calculate grid and threadgroup sizes
    # Apple Silicon SIMD width = 32; use threadgroup size as multiple of 32
    threads_per_group = 256
    grid_size = ((n + threads_per_group - 1) // threads_per_group) * threads_per_group

    output = _kernel(
        inputs={"input": input_array},
        output_shapes={"output": input_array.shape},
        output_dtypes={"output": input_array.dtype},
        grid=(grid_size, 1, 1),
        threadgroup=(threads_per_group, 1, 1),
    )

    return output["output"]


# ---------------------------------------------------------------------------
# Example Usage
# ---------------------------------------------------------------------------

if __name__ == "__main__":
    # Create test input
    n = 1024 * 1024  # 1M elements
    dtype = mx.float32  # Matches {{TYPE}} = float

    input_data = mx.arange(n, dtype=dtype)

    # Warm-up run (triggers JIT compilation)
    _ = run_kernel(input_data)
    mx.eval(_)

    # Timed run
    start = time.perf_counter()
    result = run_kernel(input_data)
    mx.eval(result)
    elapsed_ms = (time.perf_counter() - start) * 1000

    # Verify output
    print(f"Kernel: {{KERNEL_NAME}}")
    print(f"Elements: {n:,}")
    print(f"First 10: {result[:10].tolist()}")
    print(f"Elapsed: {elapsed_ms:.2f} ms")
