// main.swift — {{PROJECT_NAME}}
// Metal compute entry point
// Generated by gpu-forge

import Metal
import Foundation

// MARK: - Device Setup

guard let device = MTLCreateSystemDefaultDevice() else {
    fatalError("Metal is not supported on this device")
}
print("GPU: \(device.name)")

// MARK: - Load Metal Library

// Load the default Metal library (compiled .metal files)
guard let library = device.makeDefaultLibrary() else {
    // Fallback: load from explicit .metallib path
    // let library = try device.makeLibrary(filepath: "path/to/default.metallib")
    fatalError("Failed to load Metal library")
}

// MARK: - Create Compute Pipeline

guard let function = library.makeFunction(name: "{{KERNEL_NAME}}") else {
    fatalError("Failed to find kernel function '{{KERNEL_NAME}}'")
}

let pipelineState: MTLComputePipelineState
do {
    pipelineState = try device.makeComputePipelineState(function: function)
} catch {
    fatalError("Failed to create pipeline state: \(error)")
}

// MARK: - Create Command Queue

guard let commandQueue = device.makeCommandQueue() else {
    fatalError("Failed to create command queue")
}

// MARK: - Allocate Buffers

let elementCount = 1024 * 1024  // 1M elements
let bufferSize = elementCount * MemoryLayout<Float>.stride

// Input buffer — CPU writes, GPU reads
guard let inputBuffer = device.makeBuffer(length: bufferSize, options: .storageModeShared) else {
    fatalError("Failed to create input buffer")
}

// Output buffer — GPU writes, CPU reads
guard let outputBuffer = device.makeBuffer(length: bufferSize, options: .storageModeShared) else {
    fatalError("Failed to create output buffer")
}

// Fill input data
let inputPointer = inputBuffer.contents().bindMemory(to: Float.self, capacity: elementCount)
for i in 0..<elementCount {
    inputPointer[i] = Float(i)
}

// MARK: - Encode Compute Command

guard let commandBuffer = commandQueue.makeCommandBuffer() else {
    fatalError("Failed to create command buffer")
}

guard let encoder = commandBuffer.makeComputeCommandEncoder() else {
    fatalError("Failed to create compute encoder")
}

encoder.setComputePipelineState(pipelineState)
encoder.setBuffer(inputBuffer, offset: 0, index: 0)
encoder.setBuffer(outputBuffer, offset: 0, index: 1)

// MARK: - Calculate Threadgroup Size

// Apple Silicon SIMD width is 32 threads
let simdWidth = 32
let maxThreadsPerGroup = pipelineState.maxTotalThreadsPerThreadgroup
// Choose threadgroup size as a multiple of SIMD width (32)
let threadsPerGroup = min(maxThreadsPerGroup, 256)
let threadgroupSize = MTLSize(width: threadsPerGroup, height: 1, depth: 1)

// Total threads to cover all elements
let gridSize = MTLSize(width: elementCount, height: 1, depth: 1)

encoder.dispatchThreads(gridSize, threadsPerThreadgroup: threadgroupSize)
encoder.endEncoding()

// MARK: - Commit and Wait

let startTime = CFAbsoluteTimeGetCurrent()
commandBuffer.commit()
commandBuffer.waitUntilCompleted()
let elapsed = (CFAbsoluteTimeGetCurrent() - startTime) * 1000

// MARK: - Read Results

if let error = commandBuffer.error {
    print("Compute error: \(error)")
} else {
    let outputPointer = outputBuffer.contents().bindMemory(to: Float.self, capacity: elementCount)
    print("First 10 results:")
    for i in 0..<10 {
        print("  [\(i)] = \(outputPointer[i])")
    }
    print("Kernel '{{KERNEL_NAME}}' completed in \(String(format: "%.2f", elapsed)) ms")
    print("Elements processed: \(elementCount)")
}
