// exploits_v4.metal -- Creative Metal tricks: texture hardware, SIMD ballot,
// and other non-standard compute patterns.
//
// These exploit DIFFERENT hardware units beyond the standard ALU pipeline.

#include <metal_stdlib>
#include "types.h"
using namespace metal;

// ============================================================================
// Experiment 1: Texture Hardware as Free Interpolation
//
// The Texture Mapping Unit (TMU) is a SEPARATE fixed-function hardware block.
// It does bilinear interpolation, format conversion, and address clamping
// with ZERO ALU cost. When you call texture.sample(), the TMU works while
// the ALU can do other things.
//
// Compare: TMU bilinear interpolation (hardware, free)
//     vs   Manual lerp in compute (ALU-bound)
//
// Use case: Signal upsampling, LUT interpolation, image resizing.
// ============================================================================

kernel void exploit_texture_interp(
    texture2d<float, access::sample> tex [[texture(0)]],
    device float*        output [[buffer(0)]],
    constant ExploitParams& params [[buffer(1)]],
    uint tid [[thread_position_in_grid]])
{
    if (tid >= params.element_count) return;

    constexpr sampler s(filter::linear,
                        address::clamp_to_edge,
                        coord::normalized);

    // Sample at fractional position -- TMU does bilinear interpolation FREE
    float u = (float(tid) + 0.5f) / float(params.element_count);
    float4 val = tex.sample(s, float2(u, 0.5f));
    output[tid] = val.x;
}

kernel void exploit_compute_interp(
    device const float* input  [[buffer(0)]],
    device float*       output [[buffer(1)]],
    constant ExploitParams& params [[buffer(2)]],
    uint tid [[thread_position_in_grid]])
{
    if (tid >= params.element_count) return;

    // Manual bilinear interpolation -- uses ALU
    uint src_size = params.num_passes; // input array size
    float u = float(tid) / float(params.element_count) * float(src_size - 1);
    uint lo = uint(u);
    uint hi = min(lo + 1, src_size - 1);
    float frac = u - float(lo);

    float v0 = input[lo];
    float v1 = input[hi];
    output[tid] = v0 + (v1 - v0) * frac;
}

// ============================================================================
// Experiment 2: SIMD Ballot -- 32x Boolean Compaction
//
// simd_ballot(condition) packs 32 booleans into a single uint32.
// This is a SINGLE INSTRUCTION that does 32x data compaction.
//
// Use cases:
//   - Filter/compact: which elements pass a predicate
//   - Histogram counting: popcount(ballot) = free bin count
//   - Communication: exchange 1 bit per lane without shared memory
//
// Compare: ballot + popcount  vs  atomic_fetch_add per element
// ============================================================================

kernel void exploit_ballot_count(
    device const uint*  input  [[buffer(0)]],
    device uint*        output [[buffer(1)]],  // per-simdgroup counts
    device atomic_uint* count  [[buffer(2)]],  // total count
    constant ExploitParams& params [[buffer(3)]],
    uint tid  [[thread_position_in_grid]],
    uint stid [[thread_index_in_simdgroup]],
    uint sgid [[simdgroup_index_in_threadgroup]],
    uint tg_id [[threadgroup_position_in_grid]])
{
    if (tid >= params.element_count) return;

    // Predicate: value > threshold (mode field used as threshold)
    bool passes = input[tid] > params.mode;

    // SIMD-level reduction: 32 threads â†’ 1 sum in a SINGLE INSTRUCTION
    // This is 32x fewer atomics than per-element counting
    uint pass_val = passes ? 1u : 0u;
    uint set_bits = simd_sum(pass_val);

    if (stid == 0) {
        // Store per-simdgroup count (32x compacted)
        uint simd_id = tg_id * 8 + sgid;
        output[simd_id] = set_bits;

        // One atomic per 32 elements instead of one per element
        atomic_fetch_add_explicit(count, set_bits, memory_order_relaxed);
    }
}

kernel void exploit_atomic_count(
    device const uint*  input  [[buffer(0)]],
    device uint*        output [[buffer(1)]],  // unused, for API compatibility
    device atomic_uint* count  [[buffer(2)]],
    constant ExploitParams& params [[buffer(3)]],
    uint tid [[thread_position_in_grid]])
{
    if (tid >= params.element_count) return;

    // Traditional: one atomic per element that passes
    if (input[tid] > params.mode) {
        atomic_fetch_add_explicit(count, 1, memory_order_relaxed);
    }
}

// ============================================================================
// Experiment 3: SIMD Matrix for Non-GEMM Tasks
//
// Apple's simdgroup_matrix hardware accelerates 8x8 matrix operations.
// But who says we have to use it for matrix multiply?
//
// Trick: Pack 64 values into an 8x8 matrix, then multiply by an identity-like
// matrix with specific patterns to get free:
//   - Transpose (swap rows/cols)
//   - Broadcast (replicate one row to all)
//   - Rotate (cyclic shift of rows)
//   - Reduction (sum all rows into one)
//
// The simdgroup_matrix multiply runs on dedicated matrix hardware.
// ============================================================================

kernel void exploit_simd_matrix_reduce(
    device const float* input  [[buffer(0)]],
    device float*       output [[buffer(1)]],
    constant ExploitParams& params [[buffer(2)]],
    uint tid  [[thread_position_in_grid]],
    uint stid [[thread_index_in_simdgroup]],
    uint sgid [[simdgroup_index_in_threadgroup]],
    uint tg_id [[threadgroup_position_in_grid]])
{
    if (tid >= params.element_count) return;

    // Load 2 values per thread (64 values per simdgroup via 8x8 matrix)
    simdgroup_float8x8 data;
    simdgroup_load(data, input + (tid / 32) * 64, 8);

    // Multiply data * data using dedicated matrix hardware
    // data * data = element-wise squared norms via 8x8 matmul
    simdgroup_float8x8 result;
    simdgroup_multiply(result, data, data); // data * data = squared norms

    // Store first column of result (contains the sums)
    if (stid < 8) {
        uint out_base = (tg_id * 8 + sgid) * 8;
        // Use simdgroup_store to write result
        simdgroup_store(result, output + out_base, 8);
    }
}

// ============================================================================
// Experiment 4: GPU Byte Search (Pattern Matching)
//
// The GPU can search through raw byte data at DRAM bandwidth.
// This simulates searching through file contents mapped via bytesNoCopy.
//
// Each thread checks 16 bytes (4 uint) for a 4-byte pattern.
// At 273 GB/s, this scans ~17 GB/s of file data per second.
//
// Compare: GPU parallel search vs CPU sequential search
// ============================================================================

kernel void exploit_byte_search(
    device const uint*   data   [[buffer(0)]],
    device atomic_uint*  count  [[buffer(1)]],
    constant ExploitParams& params [[buffer(2)]],
    uint tid [[thread_position_in_grid]])
{
    if (tid >= params.element_count) return;

    // Search for 4-byte pattern (stored in mode field)
    uint pattern = params.mode;

    // Each thread checks 4 consecutive uint values (16 bytes)
    uint base = tid * 4;
    uint matches = 0;

    for (uint i = 0; i < 4; i++) {
        uint idx = base + i;
        if (idx < params.element_count * 4) {
            if (data[idx] == pattern) {
                matches++;
            }
        }
    }

    if (matches > 0) {
        atomic_fetch_add_explicit(count, matches, memory_order_relaxed);
    }
}

// ============================================================================
// Experiment 5: Threadgroup Broadcast -- Free Data Sharing
//
// On Apple Silicon, simd_broadcast(value, lane_id) lets any lane
// broadcast its value to all other lanes in the SIMD -- for FREE.
// Combined with simd_shuffle, this enables complex data exchange
// patterns that would otherwise need threadgroup memory + barriers.
//
// Trick: Build a 32-entry lookup table INSIDE the SIMD registers.
// Each lane holds one LUT entry. Any lane can look up any value
// by broadcasting from the appropriate lane. Zero memory access!
//
// Compare: SIMD register LUT vs threadgroup memory LUT
// ============================================================================

kernel void exploit_simd_register_lut(
    device const uint* input  [[buffer(0)]],
    device uint*       output [[buffer(1)]],
    constant ExploitParams& params [[buffer(2)]],
    uint tid  [[thread_position_in_grid]],
    uint stid [[thread_index_in_simdgroup]])
{
    if (tid >= params.element_count) return;

    // Each lane holds one entry of a 32-element LUT
    // (populated from a simple hash function)
    uint my_lut_entry = (stid * 7 + 13) & 0xFF;

    uint key = input[tid];

    // 8 dependent lookups using SIMD broadcast instead of memory
    uint val = simd_broadcast(my_lut_entry, key & 0x1F);
    val = simd_broadcast(my_lut_entry, (val ^ key) & 0x1F);
    val = simd_broadcast(my_lut_entry, (val ^ (key >> 5)) & 0x1F);
    val = simd_broadcast(my_lut_entry, (val ^ (key >> 10)) & 0x1F);
    val = simd_broadcast(my_lut_entry, (val ^ (key >> 15)) & 0x1F);
    val = simd_broadcast(my_lut_entry, (val ^ (key >> 20)) & 0x1F);
    val = simd_broadcast(my_lut_entry, (val ^ (key >> 25)) & 0x1F);
    val = simd_broadcast(my_lut_entry, (val ^ key) & 0x1F);

    output[tid] = val;
}

kernel void exploit_tg_memory_lut(
    device const uint* input  [[buffer(0)]],
    device uint*       output [[buffer(1)]],
    constant ExploitParams& params [[buffer(2)]],
    uint tid  [[thread_position_in_grid]],
    uint ltid [[thread_position_in_threadgroup]])
{
    if (tid >= params.element_count) return;

    // Traditional: 32-entry LUT in threadgroup memory
    threadgroup uint lut[32];

    // Populate LUT (same values as SIMD version)
    if (ltid < 32) {
        lut[ltid] = (ltid * 7 + 13) & 0xFF;
    }
    threadgroup_barrier(mem_flags::mem_threadgroup);

    uint key = input[tid];

    // Same 8 dependent lookups but via threadgroup memory
    uint val = lut[key & 0x1F];
    val = lut[(val ^ key) & 0x1F];
    val = lut[(val ^ (key >> 5)) & 0x1F];
    val = lut[(val ^ (key >> 10)) & 0x1F];
    val = lut[(val ^ (key >> 15)) & 0x1F];
    val = lut[(val ^ (key >> 20)) & 0x1F];
    val = lut[(val ^ (key >> 25)) & 0x1F];
    val = lut[(val ^ key) & 0x1F];

    output[tid] = val;
}
