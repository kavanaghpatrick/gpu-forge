# gpu-search-overhaul-3

## Original Goal
Fix 3 root causes of gpu-search being 25-34x slower than GPUripgrep. (1) Remove 100K chunk cap in content.rs — dispatch all 6.39M chunks in one GPU call instead of 64 serial batches (6.6s → ~200ms). (2) Move line number resolution to GPU kernel — add line_number field to match output, compute by counting newline bytes before match offset, eliminate 3.6s CPU resolve entirely. (3) Pre-build chunk metadata at index time and store in GCIX format so it's mmap'd and ready, not rebuilt every search (20ms per keystroke → 0ms). Expected result: search drops from 10.4s to <200ms for kolbey across 21GB.

## Phase
Quick mode — auto-generating all artifacts

## Completed Tasks
- [x] 1.1 Remove 100K chunk cap and add dynamic metadata buffer resizing
- [x] 1.2 Eliminate serial batch loop in search_zerocopy

## Current Task
Awaiting next task

## Learnings
- device field on ContentSearchEngine had #[allow(dead_code)] — removed it since ensure_metadata_capacity now uses self.device
- ensure_metadata_capacity uses the same MTLResourceOptions::StorageModeShared as initial allocation
- Single-dispatch replaces batch loop: write all chunk_metas at once, single GPU dispatch, single collect_results call
- Removed batch-local byte_offset translation loop — with single dispatch, chunk_index from GPU is already global

## Next
Task 1.3 - Add file-relative line number computation to zerocopy kernel
