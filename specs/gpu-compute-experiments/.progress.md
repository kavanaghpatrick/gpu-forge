---
spec: gpu-compute-experiments
basePath: ./specs/gpu-compute-experiments
phase: tasks
task: 1/52
updated: 2026-02-17
---

# Progress: gpu-compute-experiments

## Original Goal

Build a suite of 16 GPU compute benchmark experiments on Apple Silicon M4 Pro (273 GB/s, 20 GPU cores) to measure real-world speedups across key primitive categories: sort, scan, reduce, histogram, matmul, relational operations, and consumer app workloads. Each experiment compares GPU Metal vs CPU baseline. Results determine which layers of metal-forge-compute to prioritize.

## Completed Tasks

- [x] 1.1 Create workspace and forge-primitives crate skeleton

## Current Task

Awaiting next task

## Learnings

- Existing gpu-query shaders (filter.metal, compact.metal, aggregate.metal) are production-quality and reusable
- Inference pipeline achieved 462 tok/s decode on M4 Pro, validating Metal dispatch infrastructure
- Decoupled lookback and OneSweep DEADLOCK on Apple Silicon - use reduce-then-scan instead
- Single command buffer batching was key for inference perf (91â†’1 cmdbuf)
- Page-aligned buffers enable zero-copy via makeBuffer(bytesNoCopy:)
- Task planning: 52 tasks across 8 phases (POC, Foundation, Query Ops, Consumer, Run All, Testing, Quality, PR)
- Task planning: metal-forge-compute/ dir exists but only has an ai/ subdir -- all files are new creation
- Task planning: gpu-query/shaders/ has 11 .metal files with established patterns (aggregate.metal 3-level reduction, compact.metal atomic counter, filter.metal function constants)
- Task planning: build.rs pattern is identical across gpu-query and particle-system -- xcrun metal -c -> .air, xcrun metallib -> .metallib
- Task planning: Critical dependency chain: scan -> compact AND sort -> groupby -> pipeline. Must build scan first
- Task planning: Radix sort highest complexity (8 passes x 3 dispatches), sort experiment depends on scan kernels for histogram prefix sum
- Task planning: 65536-bin histogram may need tiling fallback if threadgroup memory > 32KB
- Task planning: No existing Cargo workspace at metal-forge-compute level -- must create from scratch
- Task planning: DuckDB experiment has CLI subprocess approach (not C API) -- simpler but ~50ms startup overhead

## Blockers

- None currently

## Learnings (task 1.1)

- MTLDevice trait must be imported explicitly in pso_cache.rs for newComputePipelineStateWithFunction_error
- MetalContext library is Optional since no shaders compiled yet in task 1.1
- PsoCache simplified vs gpu-query: no function constants, just function name keyed

## Next

Task 1.2: Metal build.rs + reduce shader + types.h
