# Progress: gpu-query-perf

## Original Goal

Fix 5 critical performance bottlenecks in gpu-query that cause a 1M-row compound filter GROUP BY query to take 367ms instead of <50ms target. Bottlenecks: (1) Double CSV scan in GpuCompoundFilter, (2) QueryExecutor recreated per query, (3) CPU-side VARCHAR dictionary rebuild, (4) Schema re-inference every query, (5) Catalog re-scan every query. Three caching layers fix all five: per-query ScanCache, persistent QueryExecutor in AppState, CatalogCache with mtime+size fingerprinting. Target: warm queries <50ms.

## Reality Check (BEFORE)

**Goal type**: Fix
**Reproduction command**: `cd gpu-query && cargo test --lib`
**Exit code**: 0
**Error output**:
```
test result: ok. 494 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.11s
```

**Key issues to resolve** (performance, not test failures):
- B1: Double CSV scan in compound filters at executor.rs:379-395 (~120-150ms waste)
- B2: QueryExecutor recreated per query at ui.rs:375 / event.rs:216 (~10-25ms)
- B3: CPU VARCHAR dictionary rebuild at executor.rs:3109-3182 (~40-80ms)
- B4: Schema re-inference every query at executor.rs:3020-3028 (~2-5ms)
- B5: Catalog re-scan every query at ui.rs:345 / event.rs:215 (~1-3ms)

**Baseline**: 367ms for 1M-row compound filter GROUP BY query
**Target**: <50ms warm query

## Current Phase
tasks

## Completed Tasks
- [x] 1.1 Add scan_cache field to QueryExecutor
- [x] 1.2 Add ensure_scan_cached and execute_scan_uncached methods
- [x] 1.3 Refactor resolve_input to return table key instead of owned ScanResult
- [x] 1.4 Add file stat validation to scan cache
- [x] 1.5 Clear scan cache between query executions
- [x] 1.6 POC Checkpoint -- Verify double-scan eliminated
- [x] 2.1 Create CatalogCache module
- [x] 2.2 Add executor and catalog_cache to AppState
- [x] 2.3 Replace scan_directory calls with CatalogCache in TUI
- [x] 2.4 Replace QueryExecutor::new() calls with persistent executor
- [x] 2.5 Phase 2 Checkpoint -- Persistent executor + cached catalog
- [x] 3.1 Enable cross-query scan cache persistence
- [x] 3.2 Add .refresh command to invalidate all caches
- [x] 3.3 Phase 3 Checkpoint -- Full warm-cache verification - 67d45fd
- [x] 4.1 Unit tests for CatalogCache
- [x] 4.2 Unit tests for scan cache in executor
- [x] 4.3 Performance benchmark for warm compound filter query
- [x] 4.4 Regression test for all existing tests - (no code changes needed)

## Current Task
Awaiting next task (4.4 complete)

## Learnings
- QueryExecutor is a clean 2-field struct (GpuDevice + PsoCache) at executor.rs:254-257 -- trivial to add scan_cache HashMap
- resolve_input returns owned (ScanResult, Option<FilterResult>) -- must refactor to return String key for cache pattern
- AppState is a flat pub-field struct with 20 fields and simple new() constructor -- straightforward extension point
- scan_directory is called from 3 TUI locations: mod.rs:65, ui.rs:345, event.rs:215 -- all must be replaced
- QueryExecutor::new is called from 2 TUI locations: ui.rs:375, event.rs:216 -- both need persistent executor
- ScanResult already contains mmap + ColumnarBatch + RuntimeSchema -- no new wrapper needed for cache value
- build_csv_dictionaries stores dictionaries in ColumnarBatch.dictionaries -- cached with scan result automatically
- PsoCache in pipeline.rs uses HashMap with composite key -- ScanCache follows same pattern
- No async runtime exists; keeping synchronous is the right call for <50ms target
- Foreman analysis is exceptionally thorough (1073-line TECH.md) -- trust the architecture, execute faithfully
- scan_cache field added with dead_code warning (expected -- used in task 1.2)
- Borrow checker concern: executor.take()/put-back pattern needed when both executor and app.set_result() need &mut app
- CLI path (cli/mod.rs:254) stays per-invocation -- only TUI gets persistent state
- execute_scan had 4 callers (lines 313, 360, 372, 2689) -- all renamed to execute_scan_uncached; callers update to cache pattern in task 1.3
- ensure_scan_cached uses to_ascii_lowercase for cache key normalization -- consistent with execute_scan's eq_ignore_ascii_case lookup
- ensure_scan_cached needs &mut self (cache insert) while execute_scan_uncached stays &self -- borrow split works cleanly
- resolve_input now returns (String, Option<FilterResult>) -- callers do self.scan_cache.get(&key).unwrap() for immutable access
- GpuFilter arm in resolve_input needs remove/reinsert pattern: execute_filter takes &mut self, conflicting with &ScanResult borrow from scan_cache
- execute_aggregate and execute_aggregate_grouped take &self (not &mut), so no borrow conflict with scan_cache.get() in execute()
- execute_sort holds &ScanResult from cache but only calls &self methods (int_local_idx, float_local_idx) + disjoint field self.device -- no conflict
- GpuCompoundFilter's left+right resolve_input calls now naturally deduplicate via ensure_scan_cached -- second call is a cache hit
- execute_describe still uses execute_scan_uncached directly (separate DESCRIBE path, not through resolve_input)
- CachedScan wrapper struct was introduced alongside ensure_scan_cached but callers weren't updated -- needed .result access on all scan_cache.get() sites
- Type annotation needed for .and_then closure on dictionaries in execute_sort: |d: &Option<crate::storage::dictionary::Dictionary>|
- remove/reinsert pattern in resolve_input GpuFilter arm uses cached.result for execute_filter(&cached.result, ...) then reinserts full cached entry
- scan_cache.clear() at top of execute() is a single line addition -- within-query dedup still works because ensure_scan_cached populates cache during the query; clear just prevents cross-query stale data
- POC checkpoint verified: all 494 lib tests + 48 GPU filter integration tests + 9 compound filter integration tests pass; Phase 1 scan cache complete
- CatalogCache is straightforward: wraps scan_directory, stores Vec<TableEntry> + HashMap<PathBuf, FileFingerprint>, validates via dir mtime then per-file stat
- get_or_init_executor uses Option<QueryExecutor> + lazy init pattern; no borrow issues since it returns &mut QueryExecutor directly
- CatalogCache::new(data_dir.clone()) in AppState::new() -- clone needed since data_dir is moved into struct field
- get_or_refresh() returns &[TableEntry] borrowing self -- must .to_vec() before mutating app fields (borrow conflict)
- All 3 TUI scan_directory sites (mod.rs, ui.rs, event.rs) use .map(|s| s.to_vec()) pattern to get owned Vec<TableEntry>

- take/put-back pattern works cleanly: take executor from Option, use it, put it back before calling app.set_result() -- avoids overlapping &mut borrows
- DESCRIBE path in event.rs needed restructured match arms to separate executor use from result handling (put executor back between them)
- ui.rs pattern: store execute() result in variable, put executor back, then map_err on result -- clean separation of concerns
- Phase 2 checkpoint verified: 494 lib tests + 48 GPU filter integration tests all pass; CLI path at cli/mod.rs:254 still uses per-invocation QueryExecutor::new(); Phase 2 persistent executor + catalog cache complete
- Removing scan_cache.clear() from execute() is a 1-line deletion; file stat validation in ensure_scan_cached handles stale data automatically
- FIFO eviction uses HashMap::keys().next() for simplicity -- Rust HashMap iteration order is arbitrary (not insertion-ordered), but any-key eviction is sufficient for a small 8-entry cache
- .refresh follows DescribeTable pattern: DotCommand::Refresh -> DotCommandResult::RefreshCaches variant, handled in event.rs execute_dot_command match
- scan_cache is private on QueryExecutor -- added pub clear_scan_cache() method rather than making field pub
- Dot command infrastructure: DotCommand enum (commands.rs) + parse_dot_command + handle_dot_command -> DotCommandResult dispatched in event.rs
- Phase 3 checkpoint verified: 494 lib tests + 48 GPU filter integration tests pass; cross-query scan cache persists, file stat validation active, .refresh command clears all caches
- Scan cache tests created as integration tests in gpu-query/tests/gpu_cache.rs (requires Metal GPU); added pub scan_cache_len() accessor to QueryExecutor for test observability
- 100ms sleep before file rewrite ensures mtime differs for invalidation test on macOS APFS (1-second mtime granularity in some cases)

## Learnings (continued)
- 1M-row warm compound filter + GROUP BY benchmark: ~35-36ms, well under 50ms target
- Persistent QueryExecutor with warm scan cache is key: first call populates cache (cold), subsequent calls skip CSV scan entirely
- bench_function closure captures &mut executor -- Criterion calls it repeatedly, each iteration reuses the warm cache
- generate_sales_csv for 1M rows produces ~80MB CSV string; String::with_capacity(n_rows * 80) avoids reallocation

## Learnings (final)
- Full regression: 807 tests (498 lib + 309 integration/E2E/bench), 0 failures -- cache refactor introduced no regressions

## Next
Task 5.1: Clippy and formatting pass
