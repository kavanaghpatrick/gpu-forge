---
spec: gpu-perf-phase3
basePath: ./specs/gpu-perf-phase3
phase: tasks
task: 0/17
updated: 2026-02-15
---

# Progress: gpu-perf-phase3

## Original Goal

Implement multi-token batched forward pass (forward_prompt) to reach 1000+ tok/s prefill on SmolLM-135M Q4_0 on Apple Silicon M4. Experiments show batch=4 gives 3.9x and batch=8 gives 7.1x per-token matvec speedup via SLC cache reuse. THREE CHANGES: (1) Create multi_token_matvec_q4_0 and multi_token_matvec_q4_0_accumulate Metal shaders. (2) Add forward_prompt() method to gpu_forward_pass.rs with batched matvec + per-token cheap ops. (3) Wire into CLI and benchmark prefill tok/s.

## Completed Tasks

_No tasks completed yet_

## Current Task

Starting implementation phase

## Learnings

- `multi_token_matvec_q4_0` kernel already proven in `bandwidth_test.metal:225-281` — direct copy to production
- `set_buffer(encoder, buf, offset_bytes, index)` supports buffer offsets for per-token slicing within batch buffers
- `encode_matvec_q4_0_accumulate` pattern exists for O-proj/down-proj residual fusion — extend to multi-token
- KV cache append is inherently sequential (causal constraint) — cannot be batched
- RMSNorm (32 threads), RoPE, SiLU are cheap per-token ops not worth creating batched kernels for
- SmolLM-135M batch=128 batch buffers total ~1.3 MB (negligible vs 70 MB weights)
- `cargo clean -p metal-attention-kernels` needed when adding new .metal shader files
- Current single-token decode: 462-491 tok/s; theoretical batch=4 prefill: ~1800 tok/s; target: 1000+
- `forward_token_greedy()` pattern at line 1562 is the template for `forward_prompt()`

## Blockers

- None currently

## Next

Execute task 1.1: Create multi_token_matvec_q4_0.metal production shader
