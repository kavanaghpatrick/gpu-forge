# GPU Particle System - Progress

## Original Goal
10M+ interactive particles on Apple Silicon Metal GPU. Build a particle system that runs almost entirely on the GPU. Rust host provides only windowing, mouse input, and command buffer submission. All physics, lifecycle management, emission, and rendering happen in Metal compute and render shaders. Mouse attracts particles; clicking emits bursts.

## Interview Format
- Version: 1.0

## Intent Classification
- Type: GREENFIELD
- Confidence: high (3 keywords matched)
- Min questions: 5
- Max questions: 10
- Keywords matched: build, implement, create

## Interview Responses

### Goal Interview (from start.md)
- API Choice: objc2-metal (direct Metal control, matches plan architecture)
- Hardware Target: M4 / M4 Pro (~100 GB/s bandwidth)
- Success Criteria: 10M particles at 60fps
- Constraints: Must use Rust + Metal compute/render shaders, minimal CPU involvement
- Problem: Building new GPU particle system from scratch

### Requirements Interview (from requirements.md)
- Primary users: Personal project / demo (GPU programming showcase)
- Priority tradeoffs: GPU performance first (maximize particle count and frame rate)
- Success criteria: 10M particles @ 60fps on M4 with full mouse interaction
- Scope decisions: Full physics with particle-particle interactions, 3D perspective camera, instanced geometry rendering

### Design Interview (from design.md)
- Architecture style: GPU-centric — almost NO CPU; Rust host is minimal shell for windowing/input/command buffer submission
- Technology constraints: Use gpu-forge Metal templates (blank.metal.tmpl, reduction.metal.tmpl) as foundation for shaders
- Project location: Subdirectory gpu_kernel/particle-system/ alongside gpu-forge plugin
- Integration approach: Minimal — standalone binary, references gpu-forge knowledge/templates only

### Tasks Interview (from tasks.md)
- Testing depth: Standard — unit + integration tests
- Deployment approach: N/A — local demo project, no CI/CD needed
- Execution priority: Balanced — reasonable quality with speed
- Additional context: None

## Learnings from Research Phase

### GPU Particle Architecture
- Verified pattern across OpenGL, DirectX 11, WebGPU, Metal: 3-kernel pipeline (emit → update → cull) with atomic-based free lists
- Production implementations (Wicked Engine, Unity GPU Particles, DirectX reference) confirm feasibility at 10M+ particle scale
- Ping-pong buffer strategy eliminates synchronization barriers between compute & render passes

### Apple Silicon Specifics
- M4 Max: 546 GB/s (verified from academic benchmarking), ~100 GB/s practical sustained for particle workloads
- Family 9 (M3/M4) dual-issue FP16+FP32 in parallel enables mixed-precision physics optimization
- Dynamic Caching on Family 9 eliminates static threadgroup/device memory partitioning tradeoff
- Register file: ~208 KiB per core; <104 regs → 2 threadgroups per scheduler = higher occupancy

### Metal 4 (2025) Impact
- Unified MTL4ComputeCommandEncoder consolidates compute + blit + acceleration ops (no separate passes for chaining)
- Indirect dispatch still requires CPU encode/commit cycles; true persistent kernels not feasible
- Function constants superior to macros; #pragma unroll for loop control

### Synchronization & Atomics
- Append buffer lock-free pattern: embed atomic_uint counter at buffer start (16-byte aligned) to avoid serialization
- threadgroup_barrier(mem_flags) required for all fences; Metal has NO standalone fence without barrier
- Serial dispatch mode (1 command buffer/frame) provides implicit memory coherency on unified memory
- Metal 3.2 coherent(device) enables cross-threadgroup visibility but does NOT eliminate explicit fences

### SIMD Operations for Particles
- SIMD width: 32 threads per simdgroup (fixed on Apple GPUs)
- Hierarchical reduction pattern: thread local → SIMD-level (simd_sum, etc.) → threadgroup-level (atomic-free)
- Divergence penalty: ~70 cycles for threads taking different branches (avoid if possible)

### Critical Constraints
- 10M particles at 256 bytes/particle = 2.56 GB allocation; feasible on M4 Max (32GB) but tight on M4 Pro (16GB)
- Practical limit likely 10-15M at 60 FPS due to vertex throughput & thermal constraints (fanless devices throttle significantly)
- Threadgroup memory: 32 independent banks; avoid classical stride-based conflicts on 32-byte strides

### GPU Forge KB Integration
- queried metal-compute, msl-kernels, simd-wave, gpu-perf skills
- 140+ findings retrieved covering Metal 4, FP16 optimization, occupancy tuning, synchronization primitives
- Production pattern from MLX/llama.cpp confirmed viable: const device inputs, device outputs, atomics at buffer start

## Learnings from Design Phase

### Architecture Decisions Validated by KB
- **Single command buffer per frame** (KB 137): Recommended Apple best practice; implicit memory coherence on unified memory
- **Serial dispatch via MTLCommandQueue** (KB 138): One queue executes command buffers serially; simplifies synchronization
- **Atomic-free reduction pattern** (KB 340): Threadgroup reduction to single value avoids global atomics; applies to dead/alive list aggregation
- **Threadgroup histogram + global merge** (KB histogram.metal.tmpl): Two-phase pattern mitigates atomic contention at 10M scale
- **256-thread threadgroup size** (KB 157, 310): Multiple of 32 SIMD width on Apple GPU; optimal occupancy when <104 registers per thread

### SoA Memory Bandwidth Strategy
- **FP32 position/velocity + FP16 color/lifetime/size** reduces per-particle read+write from 96B to ~64B (validated against KB 313: SIMD shuffle bandwidth)
- At 10M × 64B × 2 × 60fps = 76.8 GB/s sustained bandwidth fits within M4's ~100 GB/s practical limit with 23% headroom
- Grid density reads (27-neighborhood per particle) add ~34 GB/frame read; total ~111 GB/s peak (tight but acceptable given 60fps target)

### GPU PRNG Avoidance
- No CPU-seeded per-frame random state (eliminates CPU→GPU sync point)
- Hash-based GPU PRNG (e.g., XOR-shift with thread ID + frame counter) deterministic but eliminates synchronization

### Atomic Contention Mitigation
- Dead list + grid populate both use threadgroup-local pre-aggregation (KB 328, 393: SIMD communication)
- Reduces global atomic call rate from 10M to 10M÷256 ≈ 40K atomics per frame; negligible contention on M4 10-core GPU

### Register Pressure Constraint
- Physics update kernel must stay <104 registers for 2 threadgroups/core occupancy (KB 157: maxTotalThreadsPerThreadgroup)
- Mixed FP32/FP16 achieves this: FP16 halves register consumption for color/lifetime/size fields
- If exceeded, split into sub-kernels (grid read phase, then physics phase) — deferred to P2 if needed

### Metal 4 vs Metal 3 Decision
- Kept Metal 3 as primary target (KB 166, 170: Metal 4 compiler/pipeline changes not yet in objc2-metal v0.3)
- KB 166: Metal 4 MTL4ComputeCommandEncoder unifies compute+blit+acceleration; objc2-metal coverage unknown; too risky for MVP
- Metal 3 serial dispatch + explicit barriers sufficient for particle system (no persistent kernels, no advanced features)

### Synchronization Primitives Selected
- **threadgroup_barrier(mem_flags::mem_threadgroup)** for threadgroup-level sync (KB 141, 393: preferred for intra-group communication)
- **No explicit MTLFence within frame** (KB 141: fences sync across encoder passes; serial dispatch eliminates need within single buffer)
- **coherent(device)** qualifier NOT used (KB 155-156: does not eliminate explicit barriers; adds complexity with minimal benefit for particle system)

### Camera + Input Latency
- Mouse position captured and unprojected CPU-side (Rust) before frame encode; force applied same frame (KB 238: <1 frame latency requirement met)
- Depth plane approach chosen over ray-cast (simpler, faster unproject; acceptable for demo)

### Progressive Scaling Trade-offs
- 1M → 2M → 5M → 10M tiers chosen to avoid 4 GB upfront (tight on M4 Pro 16GB); enables per-scale profiling
- Buffer reallocation via CPU copy (not async kernel) during frame N; swap pointer during frame N+1 presentation; acceptable 1-frame stutter
- Alternative: double-buffer growth (alloc new while old renders) adds complexity; deferred to P2 if single-frame stutter unacceptable

### Render Geometry Selection
- Billboard quads (4 vertices per instance) chosen over point sprites (higher visual quality) vs instanced meshes (vertex throughput constraint)
- Vertex shader scales quad by particle size and applies rotation for face-camera effect
- Achievable at 10M instances with indirect draw (no CPU readback of alive count)

### Indirect Args Buffer Layout
- MTLDispatchThreadgroupsIndirectArguments and MTLDrawPrimitivesIndirectArguments coexist in single buffer at different offsets
- No alignment conflict; both struct sizes <16 bytes; placed sequentially for simplicity
- Dispatch args mostly static; draw args instanceCount updated by compaction kernel

## Learnings from Requirements Phase

### Particle-Particle Interaction Scoping
- True N-body/neighbor-search infeasible at 10M: radix sort alone ~50ms, variable-length neighbor lists cause divergence (KB 265: ~70 cycles penalty)
- Grid-based density field (64^3 = 262K cells) is the viable approximation: 27-cell neighborhood reads, atomic population, pressure gradient forces
- Grid atomic contention mitigated by threadgroup histograms merged with global atomics (two-phase pattern from histogram template)
- Grid resolution (64^3 vs 128^3) is an open question requiring profiling at 10M scale

### Bandwidth Budget Validation
- SoA + FP16 for color/lifetime/size reduces per-particle footprint from ~96B to ~64B read+write
- At 64B: 10M x 64B x 2 x 60fps = 76.8 GB/s — fits M4's ~100 GB/s with 23% headroom
- Grid density field adds ~34 GB/frame read overhead (270M cell reads at 128B cache lines) — within budget but tight
- Progressive scaling essential: validate bandwidth at 1M, 2M, 5M before committing to 10M

### Atomic Contention Strategy
- Dead/alive list atomics scale poorly at 10M (KB 283: bottleneck grows with core count)
- Mitigation: threadgroup-local pre-aggregation — collect dead indices per-threadgroup, single atomic per threadgroup to global list
- Same pattern applies to grid cell population: threadgroup histogram → single merge per threadgroup

### Scope Decisions Captured
- No SPH/fluid fidelity — grid density approximation only (user accepted)
- No Metal 4 — objc2-metal coverage unknown, Metal 3/Family 9 is the target
- No texture-mapped particles — solid color with alpha (keeps fragment shader trivial)
- Depth sorting deferred to P2 — accept alpha artifacts initially
- Mouse unproject strategy (depth plane vs ray-cast) left as implementation decision

## Learnings from Task Planning Phase

### Task Dependencies & Ordering
- build.rs must produce .metallib BEFORE any GPU code can run — scaffold task (1.1) is critical path
- Window + CAMetalLayer (1.2) blocks all visual verification; must work before emission/render can be tested
- Emission kernel (1.6) + render shaders (1.7) can be developed in parallel conceptually, but render depends on having alive particles to draw
- Physics (1.9) depends on emission working; compaction (1.10) depends on physics producing alive/dead lists
- Grid (2.1) and camera (2.4) are independent of each other after POC; can be worked in either order

### Toolchain Verified
- Rust 1.93.0 (stable, well above 1.75+ requirement)
- Metal shader compiler: Apple metal version 32023.850 (macOS 15.7.2)
- `xcrun -sdk macosx metal` and `xcrun -sdk macosx metallib` both available for build.rs
- macOS 15.7.2 (Sequoia) — exceeds macOS 14+ (Sonoma) requirement

### Risk Areas Identified
- **objc2-metal CAMetalLayer attachment**: No existing Rust code in this repo to reference; will need to carefully follow objc2 examples for NSView layer manipulation. This is task 1.2 and is the highest-risk single task.
- **Compaction kernel simplification**: Full prefix scan (design spec) replaced with atomic append for POC. At 1M particles, atomic append is fine. At 10M, may need to revisit with proper prefix scan if atomic contention becomes measurable.
- **Two-phase grid histogram**: 262K bins exceeds threadgroup memory (~60KB). Design's two-phase approach needs partial histograms in global memory, which adds complexity. POC uses single-phase global atomics; upgrade only if profiling warrants it.
- **Dispatch threadgroup count**: Physics kernel dispatch needs alive_count (on GPU). POC dispatches pool_size threadgroups with guard clause. At 10M, this wastes threads. Indirect dispatch (GPU-written args) is the proper fix for Phase 2+.

### Verification Strategy
- `cargo build` validates both Rust compilation AND Metal shader compilation (via build.rs)
- `cargo test` covers unit tests (buffers, camera, input) + GPU integration tests (emission, physics, compaction)
- `timeout N cargo run --release` validates runtime behavior without requiring human interaction
- Window title HUD provides automated observable output for FPS/particle count

### POC Scope Decisions
- 42 total tasks across 5 phases (12 POC, 13 features, 7 testing, 8 quality, 3 PR lifecycle)
- POC targets 100K+ particles at 60fps (not 10M — that's Phase 2.8+)
- Grid density and mouse interaction deferred to Phase 2 (not needed to prove pipeline works)
- Simplified compaction (atomic append) avoids prefix scan complexity in POC

## Completed Tasks
- [x] 1.1 Scaffold Rust project and Metal build pipeline
- [x] 1.2 Create window with CAMetalLayer and Metal device init
- [x] 1.3 Triple-buffer semaphore ring and frame timing
- [x] 1.4 [VERIFY] Quality checkpoint: build and shader compilation
- [x] 1.5 Allocate SoA particle buffers and free lists
- [x] 1.6 GPU PRNG and emission compute kernel
- [x] 1.7 Basic vertex + fragment shaders and render pipeline
- [x] 1.8 [VERIFY] Quality checkpoint: build + shader compilation
- [x] 1.9 Physics update kernel (gravity, drag, lifetime, death)
- [x] 1.10 Alive list compaction and ping-pong swap
- [x] 1.11 [VERIFY] Quality checkpoint: full build (clean, no fixes needed)
- [x] 1.12 POC Checkpoint: particles on screen at 60fps
- [x] 2.1 Grid clear + populate kernels (density field)
- [x] 2.2 Pressure gradient force from grid density
- [x] 2.3 [VERIFY] Quality checkpoint: build + run test (clean, no fixes needed)
- [x] 2.4 3D perspective camera with orbit controls
- [x] 2.5 Mouse attraction force in physics kernel

## Current Task
Awaiting next task

### Task 2.1: Grid clear + populate kernels
- Status: COMPLETE
- Grid density buffer: 64^3 x 4B = 1.05 MB allocated in ParticlePool
- shaders/grid.metal: grid_clear_kernel (zeros 262144 cells) + grid_populate_kernel (atomic density increment)
- Dispatch order: emission -> update -> grid_clear -> grid_populate -> sync_indirect -> render
- Grid bounds set in uniforms: [-10,-10,-10] to [10,10,10]
- Runtime verified: 4 seconds, no GPU errors, all pipelines created

## Learnings
- objc2-metal v0.3 does NOT have an "all" feature; use default features (101 features enabled by default, covering all needed Metal APIs)
- MSL float3 in structs occupies 16 bytes (padded) with 16-byte alignment; Rust match uses [f32; 3] + explicit f32 padding
- Uniforms struct total: 208 bytes (both MSL and Rust sides verified to match)
- build.rs compiles .metal -> .air via `xcrun -sdk macosx metal -c` then links to .metallib via `xcrun -sdk macosx metallib`
- Metal shader compiler version: 32023.850 (macOS 15.7.2)
- objc2-quartz-core v0.3 needed for CAMetalLayer (default features include CAMetalLayer + objc2-metal integration)
- objc2-core-foundation v0.3 needed explicitly for CGSize (not re-exported from objc2-quartz-core)
- CAMetalLayer attachment to NSView uses raw objc2::msg_send! for setWantsLayer: and setLayer: to avoid objc2-app-kit v0.3 vs winit's v0.2 type conflicts
- winit 0.30 uses ApplicationHandler trait (not Event enum); create window in resumed(), render in RedrawRequested
- raw-window-handle 0.6 AppKitWindowHandle provides ns_view as NonNull<c_void>
- newLibraryWithFile_error (deprecated but simpler than URL variant) takes &NSString path directly
- NSString::from_str creates Retained<NSString> from &str in objc2-foundation v0.3
- Metal device detected: Apple M4 Pro; metallib loads from target/debug/build/*/out/shaders.metallib
- dispatch2 crate provides DispatchSemaphore with new(count), wait(timeout), signal() methods; DispatchTime::FOREVER for blocking wait
- block2 crate RcBlock::new creates heap-allocated Objective-C blocks; use RcBlock::as_ptr() to get *mut Block<F> for Metal API calls like addCompletedHandler
- MTLCommandBufferHandler type is *mut DynBlock<dyn Fn(NonNull<ProtocolObject<dyn MTLCommandBuffer>>)> - requires raw pointer, not reference
- dispatch2 and block2 must be added as direct dependencies in Cargo.toml (they are transitive deps of objc2-metal but need explicit import)
- DispatchRetained<DispatchSemaphore> implements Clone for sharing across closures (needed for completion handler)

- MTLResourceOptions::StorageModeShared is the constant for shared CPU+GPU memory in objc2-metal v0.3
- device.newBufferWithLength_options(size, MTLResourceOptions::StorageModeShared) returns Option<Retained<ProtocolObject<dyn MTLBuffer>>>
- buffer.contents() returns NonNull<c_void>; cast to *mut u8 then offset for sub-regions
- Dead/alive list layout: 16B CounterHeader (u32 count + 12B pad) then u32 indices starting at offset 16
- Total memory for 1M particles at SoA layout: ~49.6 MB (well under 200 MB limit)
- SoA buffer sizes: positions 12B, velocities 12B, lifetimes 4B (half2), colors 8B (half4), sizes 4B (half padded)

### Verification: V1.4 [VERIFY] Quality checkpoint: build and shader compilation
- Status: PASS
- Commands: cargo clippy (0), cargo build (0)
- Fixes applied: 5 clippy warnings resolved
  - build.rs: map_or -> is_some_and (clippy::unnecessary_map_or)
  - src/frame.rs: #[allow(dead_code)] on frame_index() (used in future tasks)
  - src/gpu.rs: #[allow(dead_code)] on GpuState struct (device/library used in future tasks)
  - src/types.rs: #[allow(dead_code)] on Uniforms and DrawArgs (used in future tasks)
- .metallib produced: shaders.metallib (3829 bytes) at target/debug/build/*/out/
- Duration: ~10s total

- prng.metal uses #ifndef PRNG_METAL header guard and is included by emission.metal; also compiles as standalone .air (no kernel entry points, valid for metallib linking)
- build.rs compiles ALL .metal files including prng.metal; adding rerun-if-changed for prng.metal ensures emission.metal rebuilds when PRNG changes
- MSL atomic_fetch_sub_explicit returns PREVIOUS value; allocated slot is at indices[prev-1]; guard prev_count <= 0 prevents underflow
- MTLLibrary::newFunctionWithName returns Option<Retained<ProtocolObject<dyn MTLFunction>>>; use NSString::from_str for function name
- device.newComputePipelineStateWithFunction_error creates MTLComputePipelineState from a single MTLFunction (marked deprecated in objc2-metal but works)
- computeCommandEncoder() on MTLCommandBuffer returns Option<Retained<ProtocolObject<dyn MTLComputeCommandEncoder>>>
- MTLSize fields are NSUInteger (= usize on 64-bit Apple), NOT u64
- setBuffer_offset_atIndex is unsafe and takes Option<&ProtocolObject<dyn MTLBuffer>>
- CounterHeader layout: 4 uints (16 bytes); indices start at offset [4] in uint terms (COUNTER_HEADER_UINTS)
- Emission dispatch uses main.rs render function (not frame.rs) since render loop lives in main.rs; frame.rs is FrameRing/semaphore only

- MTLRenderPipelineDescriptor::new() creates descriptor; set vertex/fragment functions, colorAttachments[0] pixel format and blend factors
- MTLBlendFactor::SourceAlpha and ::OneMinusSourceAlpha for standard alpha blending
- MTLDepthStencilDescriptor with setDepthWriteEnabled(false) and Always compare for transparent particles (no depth buffer needed for particles-only scene)
- Indirect draw: drawPrimitives_indirectBuffer_indirectBufferOffset takes MTLPrimitiveType, buffer reference, and offset
- CRITICAL: CPU readback of alive list counter between emission compute and render does NOT work — the GPU hasn't executed the compute yet when command buffer hasn't been committed
- Solution: use a tiny "sync_indirect_args" compute kernel dispatched as 1 thread after emission, which copies alive_list[0] (atomic counter) to indirect_args.instanceCount on GPU
- setVertexBuffer_offset_atIndex binds buffers for vertex shader; same API pattern as compute encoder but for render
- Billboard quad: vertex_id 0-3 with offsets (-0.5,-0.5), (+0.5,-0.5), (-0.5,+0.5), (+0.5,+0.5) as triangle strip
- Quad scaled in clip space: clip_center.xy += offset * particle_size * clip_center.w (perspective-correct scaling)
- Camera at (0,0,5) looking at origin: glam Mat4::look_at_rh + Mat4::perspective_rh(60deg, 1280/720, 0.1, 100)
- cargo clean needed when adding new .metal shader files — build.rs cache may not detect new files since it only watches existing files via rerun-if-changed

### Verification: V1.8 [VERIFY] Quality checkpoint: build + shader compilation
- Status: PASS
- Commands: cargo clippy (exit 0), cargo build (exit 0)
- Fixes applied: 1 clippy warning resolved
  - src/buffers.rs: Changed `///` doc comments to `//!` inner doc comments for module-level docs (clippy::empty_line_after_doc_comments)
- .metallib produced: shaders.metallib (19761 bytes) at target/debug/build/*/out/
- .air files: emission.air (6960B), prng.air (2384B), render.air (7184B)
- Duration: ~8s total

- Update kernel uses alive_list_a as input, alive_list_b as output; sync_indirect_args and render both read from alive_list_b
- Both alive_list_a and alive_list_b counters must be reset to 0 at frame start (CPU write before emission)
- Physics kernel reads alive_count from alive_list_a[0] (non-atomic read of the counter field) for the guard; this works because emission already completed in the previous compute encoder pass
- Update kernel has 9 buffer bindings (0-8): uniforms, dead_list, alive_list_a, alive_list_b, positions, velocities, lifetimes, colors, sizes
- POC dispatches pool_size/256 threadgroups for update; shader guards with tid < alive_count from alive_list_a counter

- CRITICAL: MSL `device float3*` arrays use 16-byte stride (sizeof(float3)=16 with padding), but Rust allocates 12 bytes per float3 → must use `packed_float3*` in shaders for 12-byte stride to match Rust SoA buffers
- Dead list atomic underflow: with uint counter, `atomic_fetch_sub` wraps to UINT_MAX; guard `prev_count <= 0u` doesn't catch wrap-around since uint is never < 0; must check `prev_count == 0 || prev_count > pool_size` to detect underflow
- Triple-buffered semaphore (MAX_FRAMES_IN_FLIGHT=3) causes race conditions when particle SoA buffers and alive/dead lists are shared across all frames; reduced to 1 for POC; triple buffering requires per-frame buffer copies or partitioned regions
- Single buffering still achieves 120 FPS on M4 Pro at ~1M particles; GPU execution time is much less than frame budget
- Ping-pong swap approach chosen over separate compact.metal shader: update kernel's atomic append IS the compaction, CPU just swaps buffer roles each frame
- get_ping_pong_lists() method on ParticlePool returns (read_list, write_list) based on bool flag; ping_pong=false means A=read/B=write, true means B=read/A=write
- Only WRITE list counter reset to 0 at frame start; READ list retains last frame's survivors, emission appends new particles alongside them
- Frame pipeline with ping-pong: emission→read_list, update reads read_list writes write_list, sync reads write_list counter, render uses write_list, then flip flag

### Verification: V1.11 [VERIFY] Quality checkpoint: full build
- Status: PASS
- Commands: cargo clippy (exit 0), cargo build (exit 0)
- Fixes applied: None needed — clean build with no warnings
- .metallib produced: shaders.metallib at target/debug/build/*/out/
- Shaders compiled: prng.metal, emission.metal, update.metal, render.metal (all 4 .metal files)
- Duration: ~8s total

### POC Checkpoint: Task 1.12
- Status: PASS
- FPS: 119-120 FPS at ~997K active particles (well above 100K target)
- Particle count: ~997K alive at steady state (1M pool minus ~3K recycling)
- Pipeline: emission → update → sync_indirect → render (4-stage compute)
- Bugs fixed:
  1. CRITICAL: MSL `float3*` arrays use 16-byte stride but buffers allocated at 12B/particle → changed to `packed_float3*` in all shaders
  2. Dead list atomic underflow: emission kernel's `prev_count <= 0u` guard fails for uint wrap-around → added `prev_count > pool_size` check
  3. Triple-buffer race condition: shared SoA buffers + 3 in-flight frames caused data corruption → changed to single buffering (MAX_FRAMES_IN_FLIGHT=1) since particle buffers are not per-frame
- Performance: 120 FPS even with single buffering on M4 Pro
- Recycling: particles born, age accumulates via FP16 half2, die at max_age (1-5s), return to dead list

- Uniforms struct grew from 208 to 224 bytes (added interaction_strength + 3 padding floats); buffer allocation is 256 bytes so no realloc needed
- Pressure gradient reads `device const uint*` (non-atomic) from grid_density in update kernel since grid is fully populated before update runs
- Dispatch order is critical: grid must be populated BEFORE update kernel reads it; emission -> grid_clear -> grid_populate -> update -> sync -> render
- Grid populate reads from read_list (same list update kernel reads), ensuring density field matches the particles being processed
- Grid density buffer uses `device atomic_uint*` for atomic increments in MSL; `device uint*` for the clear kernel (non-atomic zero writes are fine since no concurrent readers during clear)
- Grid cell index = z * 64*64 + y * 64 + x; position normalized to [0,1] via (pos - grid_min) / (grid_max - grid_min), then quantized to [0,63]
- Grid populate reads from write_list (update kernel output = this frame's survivors), NOT read_list
- Total memory with grid: 50.6 MB for 1M particles (grid adds ~1 MB)
- cargo clean needed when adding new .metal files (confirmed again from POC learning)
- winit 0.30 WindowEvent::MouseInput uses ElementState::Pressed/Released and MouseButton::Left/Right; CursorMoved gives PhysicalPosition; MouseWheel gives MouseScrollDelta::LineDelta(x,y) or PixelDelta
- OrbitCamera uses spherical coordinates: eye = target + (distance * cos(elev) * sin(azi), distance * sin(elev), distance * cos(elev) * cos(azi)); glam::Mat4::look_at_rh for view matrix

### Task 2.2: Pressure gradient force from grid density
- Status: COMPLETE
- Added interaction_strength field to Uniforms (offset 208, 4 bytes) with 12 bytes padding to reach 224 bytes total
- Update kernel now reads grid_density buffer at buffer(9) and computes 3x3x3 neighborhood pressure gradient
- Dispatch order reordered: emission -> grid_clear -> grid_populate (reads read_list) -> update (reads read_list + grid) -> sync_indirect -> render
- Grid populated from read_list (previous frame's survivors + this frame's emissions) BEFORE update kernel runs
- interaction_strength default: 0.001 (subtle density-aware spreading)
- Runtime verified: 4 seconds, no GPU errors, all pipelines created

### Verification: V2.3 [VERIFY] Quality checkpoint: build + run test
- Status: PASS
- Commands: cargo clippy (exit 0), cargo build --release (exit 0), cargo run --release (exit 0, 5s timeout)
- Fixes applied: None needed — clean build with no warnings
- Clippy: Zero warnings (only build.rs metallib info message)
- Release build: Compiled and linked successfully
- Runtime: Metal device "Apple M4 Pro" detected, metallib loaded, all 4 pipelines created (emission, update, grid clear/populate, render), 50.6 MB allocated for 1M particles
- Shaders compiled: prng.metal, emission.metal, update.metal, render.metal, grid.metal (5 .metal files)
- Duration: ~18s total (clippy + release build + run test)

### Task 2.4: 3D orbit camera with mouse controls
- Status: COMPLETE
- Created camera.rs: OrbitCamera with spherical coordinate orbit (azimuth/elevation/distance)
- Created input.rs: InputState tracking cursor position, left/right button state
- main.rs: handles CursorMoved (right-drag orbits), MouseInput (button tracking), MouseWheel (zoom)
- Camera matrices uploaded to Uniforms each frame, replacing default_camera_matrices()
- Camera aspect ratio set on window creation and updated on Resized events
- Default: azimuth=0, elevation=0.3 rad, distance=15, target=(0,0,0), FOV=60deg
- Zoom clamp: 1.0 to 100.0; elevation clamp: +/- (PI/2 - 0.01) to avoid gimbal lock
- Runtime verified: 4 seconds, no GPU errors, all pipelines created

### Task 2.5: Mouse attraction force in physics kernel
- Status: COMPLETE
- Added unproject_cursor_to_world() in input.rs: converts screen coords to NDC, inverse(proj*view) ray, intersects z=0 plane
- Replaced Uniforms _pad1/_pad2 with mouse_attraction_radius (5.0) and mouse_attraction_strength (10.0) — total stays 224 bytes
- update.metal: mouse attraction force after pressure gradient, before Euler integration
  - Inverse-square falloff: strength / max(dist^2, 0.01), clamped to 50.0
  - Only applies within attraction_radius and dist > 0.01
- main.rs render(): computes mouse_world_pos from cursor and camera matrices each frame
- Runtime verified: 4 seconds, no GPU errors, all pipelines created

## Learnings
- glam Mat4::from_cols_array_2d converts [[f32;4];4] to Mat4 for inverse computation; Vec4 truncate() gives Vec3
- Unproject pattern: NDC → inverse(P*V) * clip_point → perspective divide → ray → plane intersection
- Replacing padding fields with meaningful data in Uniforms struct is safe as long as total size stays the same and both MSL/Rust sides match

## Next
Task 2.6: Click-to-burst emission
