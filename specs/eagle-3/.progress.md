---
spec: eagle-3
basePath: specs/eagle-3
phase: design
task: 0/0
updated: 2026-02-17
---

# Progress: eagle-3

## Original Goal

Implement EAGLE-3 speculative decoding for Mistral-7B GPU inference on Apple Silicon M4 Pro. Currently at 42.6 tok/s decode, target 100+ tok/s (2.43x speedup). EAGLE-3 adds a lightweight prediction head (~144MB Q4_0) attached to internal transformer layers that predicts draft tokens WITHOUT needing a separate draft model. The head reads hidden states from layers 0, 16, and 31 (low/mid/high) and produces draft logit distributions. Multiple draft tokens (N=6) generated via autoregressive chain through the head, then verified in one batched forward_prompt_logits call through full Mistral-7B. Reuses existing speculative decode infrastructure (verification, rollback, greedy acceptance).

## Completed Tasks

- [x] Research phase (via foreman PM agent) - EAGLE-3 architecture, bandwidth analysis, risk assessment
- [x] Requirements phase (via foreman PM agent) - User stories US-5..US-8, FR-8..FR-15, NFR-8..NFR-14
- [x] Design phase (via foreman Tech agent) - Component design, data flow, file structure, implementation steps
- [x] UX/DX design (via foreman UX agent) - CLI interface, error handling, debug modes
- [x] QA strategy (via foreman QA agent) - 4-tier test strategy, tolerance table, CI integration
- [x] 1.1 Add EagleCaptureBuffers and hidden state tap to GpuForwardPass
- [x] 1.2 Create concat_buffers Metal shader
- [x] 1.3 Create eagle_head.rs with EagleHead struct and random-weight init
- [x] 1.4 Implement forward_draft_token GPU pipeline in EagleHead

- [x] 1.5 [VERIFY] Quality checkpoint: cargo build + cargo clippy
- [x] 1.6 Create eagle.rs with EagleDecoder and chain speculation loop - 4c2fd35
- [x] 1.7 Register eagle modules in lib.rs
- [x] 1.8 [VERIFY] Quality checkpoint: full workspace build + clippy
- [x] 1.9 POC end-to-end test: run EagleDecoder with random weights on Mistral-7B

## Current Task

Awaiting next task


## Completed (Phase 2)
- [x] 2.1 Create eagle_weights.rs with SafeTensors parser
- [x] 2.2 Add EagleWeightStore with SafeTensors tensor mapping
- [x] 2.3 Add EagleHead::from_weights() constructor loading real weights

## Learnings

- EAGLE-3 multi-layer feature fusion (layers 0, N/2, N-1) captures richer features than top-layer-only
- Draft head is ~1.9% of target model params (~144MB Q4_0 for Mistral-7B)
- v1 uses chain drafting (linear, no tree) to reuse existing forward_prompt_logits verification
- SafeTensors is the standard weight format for EAGLE heads on HuggingFace
- At 60% acceptance rate, projected ~237 effective tok/s (massively exceeds 100 target)
- All existing Metal kernels can be reused for EAGLE head compute
- Task planning: buffer_copy insert point is after line 495 in forward_token (after FFN down+residual), hidden_a contains post-layer hidden state
- Task planning: encode_buffer_copy() helper already exists at line 2658, takes (encoder, src, dst, count_f32_elements)
- Task planning: EagleHead needs its own PsoCache and scratch buffers -- cannot share with GpuForwardPass due to borrow conflicts
- Task planning: build.rs auto-discovers .metal files, but cargo clean -p metal-attention-kernels needed to trigger recompilation
- Task planning: GpuWeightStore exposes embed(), lm_head(), lm_head_q6k(), lm_head_q8() -- EagleHead should borrow these from target
- Task planning: GpuKVCache supports both CPU-side (append_kv) and GPU-side (encode_kv_append) append -- eagle head uses GPU-side
- Task planning: forward_prompt_logits returns Vec<Vec<f32>> -- one logit vector per position, directly usable for verification
- Task planning: existing SpecStats struct in speculative.rs can be reused as-is for EAGLE chain stats
- Task planning: POC uses F32 FC weights (not Q4_0) to simplify initial implementation -- matvec_f32_v2 kernel used
- Task planning: Eagle KV cache is tiny (1 layer, max 64 positions) -- GpuKVCache::new(device, 64, kv_dim)
- Task planning: embed_lookup pattern from gpu_forward_pass.rs line 1441 can be replicated for prev_token embedding in eagle head

## Blockers

- None currently

## Learnings (task 1.3)

- MTLBuffer contents() returns NonNull<c_void>, must use .contents().as_ptr() as *mut f32 (not direct cast)
- Private storage buffers (alloc_buffer_private) for scratch, shared (alloc_buffer) for CPU-readable argmax result
- Norm weights initialized to ~1.0 (not random) to avoid NaN during RMSNorm
- Added `mod eagle_head;` (private) to lib.rs for compilation; task 1.7 will make it `pub mod`

## Learnings (task 1.4)

- EagleHead needs `device: &'static GpuDevice` field for command buffer creation (not available in task 1.3 struct)
- Added `embed_scratch` (shared buffer for CPU embed lookup) and `final_norm` weight buffer for output projection norm
- Added `rope_theta` and `rms_norm_eps` fields (defaulting to 10000.0 and 1e-5 for POC)
- No `matvec_f32_accumulate` kernel exists; O proj + residual done as separate matvec_f32_v2 + residual_add_inplace dispatches
- Added `residual_add_inplace`, `matvec_q6_k`, `matvec_q8_0` to PSO prewarm (needed for decoder layer and lm_head variants)
- forward_draft_token pipeline: concat3 -> fc_fuse -> concat2 -> fc_concat -> copy -> decoder(rmsnorm->QKV->RoPE->KV->attn->O+res->FFN) -> final_norm -> lm_head -> argmax
- All encode_* helpers duplicated from GpuForwardPass pattern into EagleHead impl (cannot share methods across structs)

### Verification: 1.5 [VERIFY] Quality checkpoint: cargo build + cargo clippy
- Status: PASS
- Commands: cargo build --workspace (exit 0), cargo clippy --workspace -- -D warnings (exit 0)
- Fixes applied: 35 clippy errors fixed across 4 files
  - 15x manual_div_ceil -> .div_ceil()
  - 7x too_many_arguments -> #[allow(clippy::too_many_arguments)]
  - 3x dead_code methods -> #[allow(dead_code)]
  - 1x identity_op (>> 0 removed)
  - 1x let_and_return (inlined return)
  - 1x module-level #![allow(dead_code)] for eagle_head.rs (private module)
  - 2x unused variables prefixed with _
- Commit: 3c31cc7 chore(eagle): pass quality checkpoint

## Learnings (task 1.6)

- SpecStats::new() is private in speculative.rs; constructed struct directly since fields are pub
- GpuForwardPass.weight_store is private; added public accessors (embed, lm_head, lm_head_is_f32, lm_head_q6k, lm_head_q8) delegating to weight_store methods
- Eagle capture buffers from forward_token are Retained<ProtocolObject<dyn MTLBuffer>>; eagle_capture_low/mid/high return Option<&Retained<...>>
- EagleDecoder resets eagle KV cache at start of each speculation round (fresh chain per round)
- Verification uses target.forward_prompt_logits (batched) same as SpeculativeDecoder
- Rollback logic: on rejection at position k, rollback target to target_pos_before + k + 1

### Verification: 1.8 [VERIFY] Quality checkpoint: full workspace build + clippy
- Status: PASS
- Commands: cargo build --workspace (exit 0), cargo clippy --workspace -- -D warnings (exit 0)
- No fixes needed: clean pass after tasks 1.6 and 1.7
- Duration: ~1s (incremental build)

## Learnings (task 1.9)

- Model file is at models/mistral-7b-v0.1.Q4_0.gguf (relative to workspace root), not /Users/patrickkavanagh/models/
- Workspace root cargo test needs `-p metal-attention` to find test targets in subcrates
- Random weights produce 0% acceptance rate as expected (114 drafted, 0 accepted across 19 rounds)
- End-to-end pipeline runs ~10s for 20 tokens in debug mode (includes model load time)
- POC Phase 1 complete: all 9 tasks done, EAGLE-3 infrastructure validated

## Learnings (tasks 2.1 + 2.2)

- memmap2 already in workspace Cargo.toml, just needed `memmap2.workspace = true` in crate
- serde_json already present in crate dependencies
- SafeTensors format: 8-byte LE u64 header_size + JSON header + tensor data at offset 8+header_size
- EAGLE HF weights typically BF16: bf16_to_f32 is simple `(u16 as u32) << 16` -> f32::from_bits
- Also handle F16 via `half::f16::from_bits(bits).to_f32()`
- Clippy requires `.is_multiple_of()` instead of `% N != 0` (Rust 1.93)
- EagleWeightStore validates all 11 tensor names and shapes against target_hidden_size
- Task 2.4 (register eagle_weights in lib.rs) done early since trivial

## Learnings (task 2.3)

- EagleHead::from_weights() moves weight buffers from EagleWeightStore (no clone/copy)
- Scratch buffers and KV cache still freshly allocated using target model dimensions
- rope_theta and rms_norm_eps inherited from target GpuForwardPass accessors
- final_norm initialized to all 1.0 (identity) since EAGLE SafeTensors may not include it
- EagleDecoder::new() uses num_layers() to compute mid/high capture layers generically (0, N/2, N-1)

## Next

Task 2.4 or next unchecked task
