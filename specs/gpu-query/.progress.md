# Progress: gpu-query

## Original Goal

Build a GPU-native local data analytics engine ("gpu-query") for Apple Silicon M4 laptops. The tool lets users point at a directory of files (JSON, CSV, logs, Parquet, plain text) and query them like a database in milliseconds — BigQuery-class performance on local files with zero data copying. Core architecture: files are mmap'd directly as Metal buffers (zero-copy via makeBuffer bytesNoCopy), GPU persistent compute kernels parse/index/query data at SSD bandwidth, columnar SoA storage in GPU memory, SQL-like query interface with GPU-compiled filters and simdgroup aggregations, and a full dashboard TUI with gradients for interactive results. The CPU does nothing except present results.

## Source Context

Detailed foreman-spec analysis available at:
- ai/tasks/spec/PM.md (584 lines, 26 KB findings)
- ai/tasks/spec/UX.md (1024 lines, 21 KB findings)
- ai/tasks/spec/TECH.md (1673 lines, 50+ KB findings)
- ai/tasks/spec/QA.md (1190 lines, 16 KB findings)
- ai/tasks/spec/OVERVIEW.md (executive summaries)

## Key Decisions (from Foreman Q&A)

- Target audience: Data engineers
- File formats: Parquet + CSV + JSON
- Query planner: Custom minimal MVP, DataFusion Phase 2
- Performance: Tiered (100M M4, 1B M4 Pro, 10B M4 Max)
- Default mode: Full Dashboard TUI
- CPU comparison: Always shown
- Theme: Gradients — "make it look sick"
- Autocomplete: Rich from start
- Shaders: AOT via build.rs
- Strings: Adaptive dictionary encoding
- Metal API: Metal 3 baseline + Metal 4 opt-in
- Oracle: Golden files for MVP
- Perf gate: 15% blocks, 5% warns
- Fuzzing: Parser-only (CSV + JSON)

## Phase Status

- [x] Research (via foreman-spec PM + TECH agents, synthesized to ralph-specum format)
- [x] Requirements (via foreman-spec PM + UX agents, synthesized to ralph-specum format)
- [x] Design (via foreman-spec TECH agent, synthesized to ralph-specum format)
- [x] Tasks (40 tasks across 5 phases, POC-first structure)
- [ ] Execution

## Completed Tasks
- [x] 1.1 Scaffold project and build.rs
- [x] 1.2 Metal device init and GPU types
- [x] 1.3 mmap + zero-copy Metal buffer
- [x] 1.4 CSV metadata reader (CPU-side)
- [x] 1.5 GPU CSV parser kernel (newline detection + field extraction)
- [x] 1.6 GPU column filter kernel (WHERE clause)
- [x] 1.7 GPU aggregation kernel (COUNT/SUM)
- [x] 1.8 SQL parser integration
- [x] 1.9 GPU execution engine (end-to-end query)
- [x] 1.10 POC Checkpoint
- [x] 2.1 Parquet reader (CPU metadata + GPU decode)
- [x] 2.2 JSON parser kernel (NDJSON)
- [x] 2.3 Full aggregation kernel (SUM, AVG, MIN, MAX, GROUP BY)
- [x] 2.4 Radix sort kernel (ORDER BY)
- [x] 2.5 Indirect dispatch and prepare_dispatch kernel
- [x] 2.6 Schema inference kernel
- [x] 2.7 Dictionary encoding for strings
- [x] 2.8 Compound predicates (AND/OR) and stream compaction
- [x] 2.9 Batched query execution for large files
- [x] 2.10 Query optimizer (column pruning + predicate pushdown)
- [x] 2.11 Non-interactive CLI mode
- [x] 3.1 ratatui setup with gradient rendering
- [x] 3.2 Query editor with syntax highlighting and autocomplete - f92b344
- [x] 3.3 Results table with streaming pagination
- [x] 3.4 GPU status dashboard and metrics

## Current Task
Awaiting next task

## Learnings

- Comprehensive foreman-spec analysis already completed: PM.md (584 lines), UX.md (1024 lines), TECH.md (1673 lines), QA.md (1190 lines), OVERVIEW.md covering complete architecture with 110+ KB citations
- particle-system codebase provides direct reuse patterns: build.rs AOT compilation, #[repr(C)] struct layout tests, buffer allocation (alloc_buffer helper), indirect dispatch (DispatchArgs), compute encoder helpers (per-pass pattern)
- All analytics kernels are memory-bandwidth-bound (operational intensity well below M4 ridge point of ~24 FLOPS/byte) -- GPU advantage comes from massive bandwidth (100-546 GB/s) vs CPU (~60 GB/s)
- mmap+bytesNoCopy is HIGH risk (undocumented by Apple) but validated by MLX and llama.cpp -- fallback copy path needed (~1ms/GB)
- SSD bandwidth is the real cold-query bottleneck (3-7 GB/s), not GPU. Warm queries at memory bandwidth are 10-100x faster
- Parquet is the easiest format (already columnar), CSV is medium (GPU row detection), JSON is hardest (structural indexing ala GpJSON)
- Function constant specialization [KB #210, #202] eliminates branches at compile time -- 84% instruction reduction -- key to query-specific kernel performance
- No persistent kernels on Metal [KB #440] -- must use batched dispatches chained in command buffers, with 1GB batch limit for watchdog safety [KB #441]
- POC-first task structure: 10 tasks to prove end-to-end GPU query pipeline, then 11 core engine tasks, then 10 TUI tasks, then 7 test tasks, then 2 PR tasks
- build.rs handles zero .metal files gracefully by generating a stub shader; future tasks adding .metal files will automatically be compiled
- gpu-query is a standalone crate (no workspace), same as particle-system
- parquet crate v54 with arrow feature pulls in significant deps (~160 packages total); build takes ~41s cold
- Shared MSL types.h defines: FilterParams (40B), AggParams (16B), SortParams (16B), CsvParseParams (24B), DispatchArgs (12B), ColumnSchema (8B)
- Rust FilterParams uses actual types.h field names (compare_value_int, compare_value_float, row_count, column_stride, null_bitmap_present, compare_value_int_hi) not the task description names which were approximate
- End-to-end GPU query pipeline works: SQL parse → LogicalPlan → PhysicalPlan → GPU CSV parse → GPU filter → GPU aggregate → formatted result
- QueryExecutor connects all stages: ScanResult (mmap+CSV parse), FilterResult (bitmask+match_count), QueryResult (columns+rows)
- CPU-side schema inference from first data row (i64, f64, varchar detection) works for type-routing to correct GPU kernels
- All-ones bitmask builder for unfiltered aggregation avoids special-casing in aggregate kernels
- End-to-end verified: SELECT count(*), sum(amount) FROM sales WHERE amount > 100 → 5, 1600 (correct)
- GpuDevice is compute-only (no CAMetalLayer, no render pipeline) unlike particle-system's GpuState
- 16 layout tests verify all 5 struct sizes, alignments, and byte-level field offsets
- bytesNoCopy works on Apple Silicon with 16KB page-aligned mmap regions -- zero-copy confirmed (buffer.contents() points to same mmap'd data)
- newBufferWithBytesNoCopy requires NonNull<c_void>, mapped_len (page-aligned), MTLResourceOptions, and optional deallocator block -- pass None for deallocator when MmapFile owns the mapping
- tempfile crate added as dev-dependency for test temp files
- CSV delimiter detection uses frequency analysis across comma/tab/pipe candidates -- highest count wins, defaults to comma
- format_detect priority: PAR1 magic > JSON content ({/[) > extension-based > CSV default
- catalog.scan_directory is non-recursive (immediate children only), skips Unknown formats, sorts by table name
- 41 tests total for io::csv (17), io::format_detect (17), io::catalog (7)
- Metal Shading Language does NOT support `double` (64-bit float) -- must use `float` (32-bit) for GPU-side float columns. types.h FilterParams.compare_value_float changed to compare_value_float_bits (long) to avoid double in MSL
- GPU CSV parser is two-pass: (1) csv_detect_newlines scans all bytes in parallel for '\n', stores offsets via atomic_fetch_add; (2) csv_parse_fields processes one row per thread, splits by delimiter, parses int/float fields into SoA buffers
- Atomic newline offsets are unordered -- must sort on CPU between pass 1 and pass 2
- SoA stride in shader MUST match host-side ColumnarBatch.max_rows -- initially had a bug where shader used clamped num_data_rows but host allocated with larger max_rows. Fixed by using params.max_rows (= batch.max_rows) as soa_stride unconditionally
- GpuDevice.find_metallib() needed fix: test binaries run from target/debug/deps/ but build output is in target/debug/build/. Added parent directory search
- objc2-metal 0.3 requires explicit trait imports (MTLDevice, MTLBuffer, MTLCommandBuffer, MTLCommandEncoder, MTLComputeCommandEncoder, MTLComputePipelineState) for methods to be in scope
- MTLSize uses NSUInteger (= usize on 64-bit), not u64
- setBuffer_offset_atIndex is unsafe in objc2-metal 0.3, but dispatchThreadgroups_threadsPerThreadgroup is safe
- encode.rs helpers: make_pipeline, make_command_buffer, dispatch_1d, dispatch_threads_1d, alloc_buffer, alloc_buffer_with_data, read_buffer, read_buffer_slice
- storage module: RuntimeSchema (column names + types), ColumnarBatch (Metal buffers for SoA int/float columns), DataType enum (Int64/Float64/Varchar/Bool/Date)
- 75 tests total: 69 lib + 6 GPU CSV integration tests
- Metal function constants compile into metallib correctly via AOT (build.rs xcrun metal -c), but newFunctionWithName_constantValues_error must be used at runtime to specialize -- newFunctionWithName alone will find the function but without constants resolved
- MTLFunctionConstantValues.setConstantValue_type_atIndex takes NonNull<c_void> for value, MTLDataType for type, and NSUInteger for index; needs MTLDataType::UInt for uint constants and MTLDataType::Bool for bool constants
- After adding new .metal files, cargo clean may be needed if build.rs doesn't detect the new file (rerun-if-changed=shaders/ should catch it but incremental builds may cache the old metallib)
- PsoCache pattern: HashMap<PsoKey, Retained<ProtocolObject<dyn MTLComputePipelineState>>> keyed by function name + serialized constant values
- Bitmask output: 1-bit per row stored as uint32 words; atomic_fetch_or_explicit for thread-safe bit setting; simd_sum + atomic_fetch_add for efficient match counting
- 95 tests total: 73 lib + 6 GPU CSV integration + 16 GPU filter integration
- Metal simd_shuffle_down does NOT support long/int64 -- must split into int2 (lo/hi) halves, reduce each with simd_shuffle_down, and track carry for proper 64-bit addition
- aggregate_count: one thread per bitmask word, popcount + simd_sum + threadgroup reduce + atomic_fetch_add (all uint32 = simple)
- aggregate_sum_int64: one thread per row, 64-bit SIMD reduction via int2 halves with carry, threadgroup reduction via lo/hi uint arrays, global atomic via split lo/hi with carry propagation
- Metal lacks atomic_long, so 64-bit atomic accumulation requires split into two atomic_uint (lo + hi) with carry from lo overflow propagated to hi
- 115 tests total: 73 lib + 6 GPU CSV integration + 16 GPU filter integration + 20 GPU aggregate integration
- sqlparser 0.53: FunctionArg has Unnamed, Named, and ExprNamed variants; GroupByExpr::Expressions takes (exprs, modifiers); OrderBy has exprs field directly; no OrderByKind enum
- SQL module: 49 tests covering types (8), logical_plan (6), physical_plan (12), parser (23 including parse-to-physical round trips)
- PhysicalPlan has GpuCompoundFilter for AND/OR predicates -- both sides share same input scan, executor combines bitmasks
- 164 tests total: 122 lib + 6 GPU CSV integration + 16 GPU filter integration + 20 GPU aggregate integration
- POC CHECKPOINT PASSED: 1M-row GPU query verified against CPU reference -- SELECT count(*), sum(amount) FROM sales_1m WHERE amount > 500 → count=499403, sum=374769525 (exact match)
- POC performance: ~50ms wall time for 1M-row filtered aggregate query (12MB CSV) including process startup, Metal init, mmap, CSV parse, filter, aggregate
- Full pipeline proven: SQL string → sqlparser → LogicalPlan → PhysicalPlan → mmap zero-copy → GPU CSV parse (2-pass) → GPU filter (function constant specialization) → GPU aggregate (hierarchical SIMD reduction) → formatted result
- Phase 1 complete: 10/10 POC tasks done, 164 tests passing, end-to-end GPU query pipeline verified at scale
- parquet crate v54 writer API: SerializedColumnWriter has .typed::<Int64Type>().write_batch() and .close() -- no close_column on row group writer
- parquet crate v54 reader API: read_records takes &mut Vec<T> (not pre-allocated slices); Vec is extended internally by the reader
- Parquet reader approach: CPU reads metadata+column data via parquet crate, uploads to Metal buffers directly (no GPU decode kernels needed for plain encoding since CPU reader handles decompression)
- Column pruning works: read_columns accepts optional needed_columns list, only reads and returns requested columns
- execute_parquet_scan: reads all columns, writes directly to ColumnarBatch int_buffer/float_buffer at correct SoA offsets, reuses existing filter/aggregate GPU pipeline
- Metal shader parquet_decode.metal compiled but not yet used at runtime -- CPU-side decoding is sufficient for POC/Phase 2; GPU decode kernels ready for future optimization
- 177 tests total: 125 lib + 6 GPU CSV + 16 GPU filter + 20 GPU aggregate + 10 GPU Parquet
- NDJSON parser approach: two-pass GPU pipeline (json_structural_index for newline detection + json_extract_columns for field extraction), same pattern as CSV parser
- NDJSON metadata: CPU reads first line, simple JSON parser extracts field names and infers types (int/float/varchar)
- NDJSON row offsets: unlike CSV (which has header), NDJSON rows start at byte 0; row offsets = [0, after_newline_0, after_newline_1, ...]
- Reused CsvParseParams struct for JSON (delimiter=0, has_header=0) to avoid adding new GPU struct
- After adding new .metal files, cargo clean required to rebuild metallib (incremental build caches old metallib)
- 195 tests total: 133 lib + 6 GPU CSV + 16 GPU filter + 20 GPU aggregate + 10 GPU JSON + 10 GPU Parquet
- Metal lacks 64-bit atomics for MIN/MAX -- CAS on split lo/hi pair is non-atomic and produces wrong results under contention with multiple threadgroups. Solution: write per-threadgroup partials to array, do final MIN/MAX reduction on CPU. GPU handles SIMD + threadgroup reduction (256x reduction), CPU handles final ~4-16 partials.
- aggregate_sum_float uses float CAS loop for global atomic (reinterpret float as uint via as_type<>). Works because threadgroup reduction reduces contention to ~4-16 CAS ops.
- AVG implemented as SUM/COUNT on CPU side -- run both GPU kernels and divide. No new Metal kernel needed.
- GROUP BY implemented CPU-side: read group column from GPU buffer, HashMap grouping, per-group aggregate computation. Avoids GPU hash table complexity for POC.
- Per-threadgroup partials pattern: GPU kernel writes tg_result to partials[tg_idx], host reads back array and does final reduction. Clean separation of GPU parallel reduction from CPU final merge.
- 222 tests total: 133 lib + 6 GPU CSV + 47 GPU aggregate + 16 GPU filter + 10 GPU JSON + 10 GPU Parquet
- ORDER BY implemented CPU-side for POC: execute inner plan (scan + optional filter), read all column data from GPU buffers, sort row indices using Rust sort_by, build row-oriented result. Avoids GPU radix sort complexity.
- sort.metal has placeholder kernels (radix_sort_histogram, radix_sort_scan, radix_sort_scatter) with correct SortParams bindings for future GPU acceleration
- GpuSort in execute(): materializes all columns into ColumnValues enum (Int64/Float64/Varchar), collects selected row indices from bitmask, sorts indices by sort columns, builds result rows
- resolve_input() needed GpuSort pass-through arm to handle Sort wrapping Filter wrapping Scan chains
- 233 tests total: 133 lib + 6 GPU CSV + 47 GPU aggregate + 16 GPU filter + 10 GPU JSON + 10 GPU Parquet + 11 GPU sort
- Indirect dispatch: prepare_query_dispatch kernel reads match_count from GPU buffer, computes ceil(count/threads_per_tg) threadgroup count, writes DispatchArgs for dispatchThreadgroupsWithIndirectBuffer. Eliminates GPU→CPU→GPU round-trip.
- objc2-metal indirect dispatch method: encoder.dispatchThreadgroupsWithIndirectBuffer_indirectBufferOffset_threadsPerThreadgroup(&buffer, 0, tg_size) -- unsafe, buffer must contain 3 x uint32 (DispatchArgs)
- FilterResult refactored: match_count_buffer and dispatch_args_buffer stay GPU-resident; match_count read lazily via Cell<Option<u32>> only when CPU needs it (e.g., for display)
- Filter + prepare_dispatch in single command buffer: two compute encoders in sequence within one cmd_buf ensures implicit coherence (no barrier needed between filter output and prepare_dispatch input)
- 244 tests total: 133 lib + 6 GPU CSV + 47 GPU aggregate + 11 GPU dispatch + 16 GPU filter + 10 GPU JSON + 10 GPU Parquet + 11 GPU sort
- Enhanced infer_schema_from_csv to sample up to 100 rows (was 1 row). Type voting: if ANY row has varchar -> Varchar, if ANY has float -> Float64, else Int64. Empty fields -> nullable=true.
- NullBitmap: Vec<u32> wrapping 1-bit-per-row bitmap, matches GPU bitmask format (same as filter output). Methods: set_null, is_null, clear_null, null_count, as_words (for GPU upload).
- schema_infer.metal: placeholder GPU kernel with integer/float/varchar detection via character scanning. Ready for future GPU acceleration of 10K+ row inference.
- infer_schema_from_csv made pub for integration test access
- 271 tests total: 143 lib + 6 GPU CSV + 47 GPU aggregate + 11 GPU dispatch + 16 GPU filter + 10 GPU JSON + 10 GPU Parquet + 17 GPU schema + 11 GPU sort
- Dictionary encoding for strings: CPU-side sorted unique values -> u32 codes. Avoids GPU string comparison entirely -- becomes integer comparison via existing filter kernel
- ColumnarBatch extended with string_dict_buffer (u32 codes per row) and dictionaries Vec<Option<Dictionary>> (one per global column index)
- String WHERE clause: look up comparison value in dictionary -> get u32 code -> re-upload dict codes as i64 to temp Metal buffer -> dispatch INT64 filter kernel with EQ on dict code
- For string values not in dictionary, short-circuit return with 0 matches (no GPU dispatch needed)
- GROUP BY on VARCHAR columns now works: read dict codes from string_dict_buffer, decode via dictionary, use as group keys in CPU-side HashMap grouping
- CSV dictionary building: after GPU parse (which handles int/float), CPU reads raw CSV again to extract VARCHAR column values, builds dictionaries, encodes to string_dict_buffer
- JSON dictionary building: similar pattern for NDJSON -- simple field extraction on CPU for string fields
- dict_build.metal is a placeholder for future GPU-side dictionary construction (sort-based dedup); current implementation is entirely CPU-side which is sufficient for <10K distinct values
- 283 tests total: 149 lib + 6 GPU CSV + 47 GPU aggregate + 11 GPU dispatch + 22 GPU filter + 10 GPU JSON + 10 GPU Parquet + 17 GPU schema + 11 GPU sort
- Compound predicates (AND/OR): execute left + right sub-filters independently, then dispatch compound_filter_and/or kernel to bitwise combine bitmasks. Both sub-filters share same scan result.
- compound_filter_and/or kernels: one thread per bitmask word, bitwise AND/OR, popcount + simd_sum for match counting. Simple and efficient.
- compact_selection kernel: bitmask to dense row indices via atomic prefix allocation + ctz bit extraction loop. Suitable for ORDER BY/SELECT * on filtered data.
- GpuCompoundFilter in resolve_input: recursively call resolve_input for left and right sub-plans, combine bitmasks with execute_compound_filter. Left side provides the ScanResult used downstream.
- 292 tests total: 149 lib + 6 GPU CSV + 47 GPU aggregate + 11 GPU dispatch + 31 GPU filter + 10 GPU JSON + 10 GPU Parquet + 17 GPU schema + 11 GPU sort
- Batched execution for GPU watchdog safety: BATCH_SIZE_BYTES=512MB threshold, split_into_chunks at newline boundaries, per-chunk GPU pipeline (parse+filter+aggregate), CPU-side merge of partial results (sum-of-sums, min-of-mins, etc.)
- Non-first CSV chunks need offset 0 prepended to row_offsets (csv_detect_newlines only records positions-after-newlines, first row of non-first chunk starts at offset 0)
- execute_with_batching detects large aggregate queries on CSV files and transparently routes to batched path; other query types fall through to standard execution
- 320 tests total: 168 lib (149 + 19 batch unit tests) + 6 GPU CSV + 47 GPU aggregate + 9 GPU batch + 11 GPU dispatch + 31 GPU filter + 10 GPU JSON + 10 GPU Parquet + 17 GPU schema + 11 GPU sort
- Query optimizer: 3-pass pipeline (column pruning -> predicate pushdown -> constant folding) on LogicalPlan before conversion to PhysicalPlan. Column pruning walks the plan tree collecting all referenced column names, then sets Scan.projection to only those columns. Predicate pushdown swaps Projection(Filter(Scan)) to Filter(Projection(Scan)). Constant folding recursively folds Expr trees (currently identity since Expr type has no arithmetic ops). Optimizer wired into main.rs between parse_query and physical_plan::plan.
- 343 tests total: 191 lib (168 + 23 optimizer unit tests) + 6 GPU CSV + 47 GPU aggregate + 9 GPU batch + 11 GPU dispatch + 31 GPU filter + 10 GPU JSON + 10 GPU Parquet + 17 GPU schema + 11 GPU sort
- CLI module: clap derive for all flags (-e, -f, -o, --format, --no-gpu, --profile, --dashboard, --cold, --theme). Non-interactive path: parse args -> resolve query (from -e, -f, or stdin pipe) -> execute -> format output (table/csv/json/jsonl) -> write to stdout or -o file -> exit
- OutputFormat enum with FromStr/Display for csv/json/jsonl/table; json_value() auto-detects int/float/null/string for proper JSON typing
- Pipe input detection via libc::isatty(STDIN_FILENO); resolve_query() tries -e, then -f, then stdin pipe
- 370 tests total: 203 lib (191 + 12 cli unit tests) + 15 e2e_cli + 6 GPU CSV + 47 GPU aggregate + 9 GPU batch + 11 GPU dispatch + 31 GPU filter + 10 GPU JSON + 10 GPU Parquet + 17 GPU schema + 11 GPU sort
- TUI module: ratatui 0.29 + crossterm 0.28, five files (mod.rs, app.rs, event.rs, gradient.rs, themes.rs). Gradient system: multi-stop RGB lerp with sample() for text coloring. Four themes: thermal (default, orange/gold), glow (neon blue/purple), ice (cool blue/cyan), mono (grayscale). AppState model holds query state, results, focus panel, theme, frame counter. Event loop: crossterm poll at 16ms (60fps), q/Ctrl+C to quit, Tab cycles focus, Esc returns to editor. Dashboard layout: 3-row vertical (title bar + content + status bar), content = 3-panel (catalog 20% | editor 30% + results 70%). Wired into main.rs --dashboard flag replacing placeholder.
- 388 tests total: 221 lib (203 + 18 tui unit tests) + 15 e2e_cli + 6 GPU CSV + 47 GPU aggregate + 9 GPU batch + 11 GPU dispatch + 31 GPU filter + 10 GPU JSON + 10 GPU Parquet + 17 GPU schema + 11 GPU sort
- Editor module: custom multi-line SQL editor widget (no tui-textarea dep) with cursor movement, insert/delete, newline, Home/End, word-at-cursor extraction, and completion application
- SQL tokenizer for syntax highlighting: regex-free char-by-char lexer handles keywords (blue), identifiers (green), string literals (yellow), numbers (magenta), operators, comments, whitespace
- Autocomplete: fuzzy matching (prefix + subsequence), 4 completion kinds (keyword/function/table/column), column completions show type + cardinality (e.g., "region [VARCHAR, 8 distinct]"), sorted by kind priority (columns > tables > functions > keywords)
- 258 lib tests total (221 + 18 editor + 19 autocomplete)
- Results table: ResultsState tracks current_page, page_size, scroll_offset, selected_row; auto-advance page on scroll past boundary; reset on new query result
- Number formatting: insert_thousands_sep on digit strings, format_i64/format_f64 handle negative/special values, format_number auto-detects int vs float vs string
- Column type detection: sample first 100 rows, if >80% non-null values parse as numeric -> treat column as numeric (right-aligned + formatted)
- NULL rendering: case-insensitive "null" or empty string -> dim gray "NULL" cell
- Column auto-width: sample header + first 200 rows, pad +2, clamp [4,40], proportional scale-down if exceeds terminal width
- Performance line: adaptive time units (us/ms/s) with formatted row count
- ratatui Table widget with Row/Cell for proper columnar rendering; replaced inline Paragraph-based results panel
- AppState.results_state added for pagination; results_state.reset() called in set_result() for clean pagination on new queries
- 288 lib tests total (258 + 30 results)
- GpuMetricsCollector: ring-buffer history (MAX_HISTORY=64 entries) for sparkline, tracks query_count, peak_memory_bytes, per-query gpu_time_ms/scan_throughput_gbps/memory_used_bytes/rows_processed/bytes_scanned
- GPU utilization estimate: throughput / M4_PEAK_BANDWIDTH_GBPS (100 GB/s); clamped 0.0..=1.0. Rough heuristic for POC, Metal Counters API can replace later
- GpuTimer wraps std::time::Instant for wall-clock GPU timing; into_metrics() computes throughput from bytes_scanned/time
- Dashboard panel: render_gpu_dashboard renders utilization bar (gradient), memory bar (gradient), stats line, avg line, sparkline history
- ratatui Sparkline widget takes &[u64] data; throughput history stored as f64 GB/s, converted to u64 MB/s for display
- Gradient bars use Unicode block characters (full block + light shade) with per-character gradient coloring
- 312 lib tests total (288 + 20 metrics + 4 dashboard)
