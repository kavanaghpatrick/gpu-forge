# Progress: gpu-query

## Original Goal

Build a GPU-native local data analytics engine ("gpu-query") for Apple Silicon M4 laptops. The tool lets users point at a directory of files (JSON, CSV, logs, Parquet, plain text) and query them like a database in milliseconds — BigQuery-class performance on local files with zero data copying. Core architecture: files are mmap'd directly as Metal buffers (zero-copy via makeBuffer bytesNoCopy), GPU persistent compute kernels parse/index/query data at SSD bandwidth, columnar SoA storage in GPU memory, SQL-like query interface with GPU-compiled filters and simdgroup aggregations, and a full dashboard TUI with gradients for interactive results. The CPU does nothing except present results.

## Source Context

Detailed foreman-spec analysis available at:
- ai/tasks/spec/PM.md (584 lines, 26 KB findings)
- ai/tasks/spec/UX.md (1024 lines, 21 KB findings)
- ai/tasks/spec/TECH.md (1673 lines, 50+ KB findings)
- ai/tasks/spec/QA.md (1190 lines, 16 KB findings)
- ai/tasks/spec/OVERVIEW.md (executive summaries)

## Key Decisions (from Foreman Q&A)

- Target audience: Data engineers
- File formats: Parquet + CSV + JSON
- Query planner: Custom minimal MVP, DataFusion Phase 2
- Performance: Tiered (100M M4, 1B M4 Pro, 10B M4 Max)
- Default mode: Full Dashboard TUI
- CPU comparison: Always shown
- Theme: Gradients — "make it look sick"
- Autocomplete: Rich from start
- Shaders: AOT via build.rs
- Strings: Adaptive dictionary encoding
- Metal API: Metal 3 baseline + Metal 4 opt-in
- Oracle: Golden files for MVP
- Perf gate: 15% blocks, 5% warns
- Fuzzing: Parser-only (CSV + JSON)

## Phase Status

- [x] Research (via foreman-spec PM + TECH agents, synthesized to ralph-specum format)
- [x] Requirements (via foreman-spec PM + UX agents, synthesized to ralph-specum format)
- [x] Design (via foreman-spec TECH agent, synthesized to ralph-specum format)
- [x] Tasks (40 tasks across 5 phases, POC-first structure)
- [ ] Execution

## Learnings

- Comprehensive foreman-spec analysis already completed: PM.md (584 lines), UX.md (1024 lines), TECH.md (1673 lines), QA.md (1190 lines), OVERVIEW.md covering complete architecture with 110+ KB citations
- particle-system codebase provides direct reuse patterns: build.rs AOT compilation, #[repr(C)] struct layout tests, buffer allocation (alloc_buffer helper), indirect dispatch (DispatchArgs), compute encoder helpers (per-pass pattern)
- All analytics kernels are memory-bandwidth-bound (operational intensity well below M4 ridge point of ~24 FLOPS/byte) -- GPU advantage comes from massive bandwidth (100-546 GB/s) vs CPU (~60 GB/s)
- mmap+bytesNoCopy is HIGH risk (undocumented by Apple) but validated by MLX and llama.cpp -- fallback copy path needed (~1ms/GB)
- SSD bandwidth is the real cold-query bottleneck (3-7 GB/s), not GPU. Warm queries at memory bandwidth are 10-100x faster
- Parquet is the easiest format (already columnar), CSV is medium (GPU row detection), JSON is hardest (structural indexing ala GpJSON)
- Function constant specialization [KB #210, #202] eliminates branches at compile time -- 84% instruction reduction -- key to query-specific kernel performance
- No persistent kernels on Metal [KB #440] -- must use batched dispatches chained in command buffers, with 1GB batch limit for watchdog safety [KB #441]
- POC-first task structure: 10 tasks to prove end-to-end GPU query pipeline, then 11 core engine tasks, then 10 TUI tasks, then 7 test tasks, then 2 PR tasks
