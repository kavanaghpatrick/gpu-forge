# Progress: gpu-query-autonomous

## Original Goal

Build a GPU-autonomous query engine achieving sub-1ms warm query latency on 1M rows by getting the CPU out of the loop entirely. Architecture: persistent Metal compute kernel with completion-handler re-dispatch, JIT Metal shader compilation, fused filter+aggregate+GROUP BY kernel, binary columnar pre-loaded data, triple-buffered work queue, zero-readback unified memory output. New AutonomousExecutor struct. Live mode ON by default, 0ms debounce. 64-group GROUP BY limit. Separate command queue.

## Reality Check (BEFORE)

**Goal type**: Greenfield (new execution architecture alongside existing)
**Reproduction command**: `cd gpu-query && cargo test --lib`
**Baseline**: 36ms warm query latency for 1M-row compound filter + GROUP BY
**Target**: <1ms warm query latency (same workload)

## Current Phase
execution

## Completed Tasks
- Spec synthesis (research.md, requirements.md, design.md, tasks.md)

## Current Task
Ready for implementation (Phase 1: Foundation)

## Learnings
- Full foreman spec analysis exists in ai/tasks/spec/ (PM.md 498 lines, UX.md 902 lines, TECH.md 1576 lines, QA.md 1312 lines)
- All Q&A decisions captured in each spec file
- Synthesis insight: 42 tasks across 7 phases, POC-first structure
- Existing codebase uses #[repr(C)] structs with MSL counterparts + comprehensive offset tests in types.rs -- autonomous types must follow same pattern
- PSO caching pattern exists in pipeline.rs -- JIT cache follows same HashMap pattern
- Filter.metal shows function constant specialization (COMPARE_OP, COLUMN_TYPE, HAS_NULL_CHECK) -- AOT fallback kernel follows this
- aggregate.metal has simd_sum_int64 helper via lo/hi split for 64-bit SIMD reductions -- reuse in fused kernel
- 32KB threadgroup memory limit [KB #22] constrains GROUP BY to 64 groups (10KB) for safe margin
- True persistent kernels NOT feasible on Metal [KB #151, #440, #441] -- must use bounded time-slice + completion-handler re-dispatch [KB #152]
- CPU-GPU memory ordering not well-defined [KB #154] -- Acquire-Release on sequence_id is critical
- Phase 2 deliberately uses waitUntilCompleted for one-shot dispatch to prove fused kernel correctness before persistent kernel in Phase 4
- Key technical decisions from Q&A: hard <1ms all 6 pillars, 0ms debounce, JIT+AOT, 64-group limit, completion-handler re-dispatch MVP, separate command queue, per-type binary buffers matching ColumnarBatch, split float tolerance (exact int, 1e-5 float), loom behind feature flag
