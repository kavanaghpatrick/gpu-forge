---
spec: gpu-search-perf
basePath: specs/gpu-search-perf
phase: research
task: 0/0
updated: 2026-02-17T23:15:00Z
---

# Progress: gpu-search-perf

## Original Goal

Optimize gpu-search-ui turbo kernel from ~20 GB/s to 60-100 GB/s on M4 by applying KB-backed Metal best practices: signed int loop indices (KB #177), 64-byte local_data (KB #1978), remove find_line_bounds/score_file_extension from GPU (KB #1980), setBytes() for pattern preloading (KB #1826), -Os shader compilation (KB #206). Move priority scoring to CPU. Target: 3-5x throughput improvement on path search from root.

## Completed Tasks
- [x] 1.1 Add PATH_SEARCH_SHADER constant and get_path_search_shader() to shader.rs
- [x] 1.2 Add GpuPathMatchResult struct and pipeline fields to GpuContentSearch
- [x] 1.4 Add score_file_extension_cpu() function

## Current Task
Awaiting next task

## Learnings

- `search_paths()` currently uses `turbo_pipeline` (turbo_search_kernel) which still calls `find_line_bounds()` + `score_file_extension()` on GPU — these are the main bottlenecks for path search since every match triggers random device memory access
- Path search doesn't need line numbers, context extraction, or GPU-side priority scoring — all of this runs on CPU from `chunk_data` already in RAM
- Overlap loading doubles register pressure (128 vs 64 bytes per thread) for marginal benefit in interactive search — GPUripgrep proves 64-byte window is sufficient
- `set_buffer()` used for 16-byte params and 64-byte pattern; `set_bytes()` would preload into uniform registers with zero latency
- `CompileOptions::new()` uses default optimization — `-Os` availability in `metal` crate needs runtime verification; fallback is separate smaller shader string
- CPU extraction does 3 String allocations per match (`from_utf8_lossy`, `trim().to_string()`, `path.clone()`) — reducible to 1
- Results Vec allocated without capacity hint despite known `result_count`
- New kernel is strictly additive — no risk to existing content/turbo/single-byte/direct kernels
- metal crate v0.33 `CompileOptions` confirmed does NOT expose `set_optimization_level()` — must use raw `msg_send![setOptimizationLevel: 1u64]` or rely on separate smaller shader compilation as the primary I-cache benefit
- `set_bytes()` signature in metal 0.33: `fn set_bytes(&self, index: NSUInteger, length: NSUInteger, bytes: *const c_void)` — index is buffer binding index, NOT byte offset
- Path search kernel can skip metadata buffer(1) entirely — chunk_index is `byte_base / CHUNK_SIZE`, derivable from thread position. Saves one device memory read per thread.
- PathMatchResult at 8 bytes (2 x u32) vs GpuMatchResult at 32 bytes (8 x u32) = 4x less GPU write bandwidth per match
- Padding bytes in load_paths are all `\n` — path_search_kernel will search into padding but `\n` never matches useful patterns (first-char early exit). Harmless.
- Switching from `from_utf8_lossy` to `from_utf8` is stricter (skips non-UTF8 paths entirely instead of replacing) — better behavior for path search since garbled paths are useless
- `score_file_extension_cpu()` uses Rust byte slice matching which is cleaner than the GPU's cascading if-else but must produce identical priority values for test compatibility
- Adding struct fields requires simultaneous initialization in `new()` for build to pass — task 1.2 included path_pipeline and path_matches_buffer init that was planned for 1.3

## Blockers

- None currently

## Learnings (Task Planning)
- MSL `match` is a keyword in some Metal compiler contexts — renamed loop variable to `match_found` in path_search_kernel to avoid potential compilation issues
- `metal` crate v0.33 re-exports `objc` via `pub extern crate objc` — `metal::objc::msg_send!` is available with no extra Cargo dependency for `-Os` compilation
- `set_bytes()` confirmed in metal 0.33 at encoder.rs:1655 — signature is `set_bytes(index, length, bytes)` where index is the buffer binding index
- `setOptimizationLevel` NOT exposed in metal 0.33 CompileOptions — must use raw `msg_send![setOptimizationLevel: 1u64]` via metal::objc
- 10 existing integration tests in test_path_search.rs cover: basic search, raw GPU match count, single path, chunk integrity, 1K paths, 200K scale, 1M scale, multi-word, real filesystem, absolute path prefix — these are the primary correctness gate
- Existing `pattern_buffer` and `params_buffer` must be kept for content search methods (`search()`, `turbo_search()`, `search_with_profiling()`) — only `search_paths()` uses `set_bytes()`
- Task ordering: shader.rs first (kernel source), then search.rs structs+fields, then new() init, then score_file_extension_cpu, then search_paths rewrite — each builds on previous
- `-Os` is a separate phase because it requires msg_send! which is riskier — POC validates without it first

## Next
Task 1.5: Rewrite search_paths() to use new path pipeline with set_bytes()
