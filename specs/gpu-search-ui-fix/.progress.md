# gpu-search-ui-fix

## Original Goal
Fix 3 critical bugs in gpu-search-ui filename search: (1) GPU context extraction truncates paths at 64 bytes, (2) paths stored without absolute prefix, (3) index rebuilds from scratch every launch. Additional: add comprehensive automated tests.

## Current Phase
execution (quick mode - all artifacts generated)

## Reality Check (BEFORE)

**Goal type**: Fix
**Reproduction command**: `cd /Users/patrickkavanagh/gpu-search-ui && cargo test --release test_profile_gpu_vs_cpu -- --nocapture --ignored`
**Exit code**: 0 (tests pass but performance data shows the bug)
**Error output**:
```
GPU vs CPU Time Breakdown (1M files, 102.9 MB)
Query (max_results)          TotalMs      Ratio Throughput  Matches
friendship (100)               3.08   GPU~100%      33.4 GB/s      100
friendship (50K)              10.45    CPU~70%       9.8 GB/s    50000
file (100)                     2.14   GPU~100%      48.0 GB/s      100
file (50K)                     7.90    CPU~73%      13.0 GB/s    50000
a (100)                        1.58   GPU~100%      65.2 GB/s      100
a (50K)                        7.63    CPU~79%      13.5 GB/s    50000
```

**All existing tests**: 9 passed, 0 failed (test_path_search.rs), 2 passed (test_integration.rs)

**Key issues to resolve**:
- Bug 1: CPU context extraction is 70-79% of total search time at 50K results (7.3ms of 10.4ms)
- Bug 2: Needs verification — code review suggests paths ARE preserved, but needs targeted test
- Bug 3: index_thread walks FS on every launch — no persistence

## POC Results (AFTER)

```
GPU vs CPU Time Breakdown (1M files, 102.9 MB)
Query (max_results)          TotalMs      Ratio Throughput  Matches
friendship (50K)               8.69    CPU≈65%      11.8 GB/s    50000
file (50K)                     6.36    CPU≈66%      16.2 GB/s    50000
a (50K)                        6.02    CPU≈72%      17.1 GB/s    50000
```

**Improvement vs BEFORE**:
- friendship(50K): 10.45ms → 8.69ms (17% faster, 9.8 → 11.8 GB/s throughput, CPU 70% → 65%)
- file(50K): 7.90ms → 6.36ms (20% faster, 13.0 → 16.2 GB/s throughput, CPU 73% → 66%)
- a(50K): 7.63ms → 6.02ms (21% faster, 13.5 → 17.1 GB/s throughput, CPU 79% → 72%)
- Tests: 10 passed (was 9+2), 0 failed

## Completed Tasks
- [x] 1.1 Add GPU-side newline scanning to turbo_search_kernel
- [x] 1.2 Update search_paths() to use GPU-provided context offsets
- [x] 1.3 Verify absolute path preservation with diagnostic test
- [x] 1.4 Add PathCache save/load to index.rs
- [x] 1.5 Integrate PathCache into app.rs index_thread
- [x] 1.6 POC Checkpoint — all tests pass, 17-21% latency improvement confirmed

## Current Task
Awaiting next task

## Phase 2 Progress
- [x] 2.1 Clean up turbo_search_kernel newline scan — extracted find_line_bounds() inline MSL function

## Learnings
- turbo_search_kernel now uses `(device const uchar*)data` to scan backward/forward for newlines from match position
- context_start is offset-within-chunk of line start; context_len is min(line_end - line_start, MAX_CONTEXT)
- column field preserved as raw byte offset for backward compatibility
- turbo_search_kernel writes raw byte offsets; CPU scans backward/forward to newlines (70-79% overhead at scale)
- content_search_kernel already does GPU-side newline scanning (lines 178-201) — proves the approach works in MSL
- load_paths() uses to_string_lossy() which preserves absolute prefix; bug 2 may be a context extraction issue not a storage issue
- chunk_data is contiguous Vec<u8> — backward scan from any abs_offset works correctly across chunk boundaries
- PathCache needs no new crates — std::fs + custom binary format sufficient
- Device buffer reads in MSL are fast on unified memory — no penalty for scattered newline scans
- MAX_CONTEXT is 512 bytes in shader.rs — sufficient for macOS paths (max ~1024)
- Existing test suite covers 5-path to 1M-path scales but lacks chunk boundary and unicode tests
- search_paths() now uses GPU-provided context_start/context_len directly — no CPU newline scanning
- abs_start = chunk_idx * CHUNK_SIZE + m.context_start; abs_end = (abs_start + context_len).min(data.len())
- All 9 path_search tests pass including 1M-path scale test — GPU offsets work correctly end-to-end
- Absolute path prefix confirmed preserved: /usr/share/ and /Users/ prefixes intact through full GPU pipeline
- Bug 2 (path prefix) confirmed NOT a bug — load_paths() + GPU context extraction preserves absolute paths correctly
- PathCache binary format: 8B magic + 4B version + 8B timestamp + 4B+N root + 4B count + per-file (4B+N path)
- PathCache uses save_to/load_from internal methods with explicit cache_dir to avoid env var races in parallel tests
- Cache location: ~/.cache/gpu-search-ui/paths.bin, expires after 3600s, validates root path match
- index_thread cache integration: load at top (early return), save after walk loop using all_collected_paths vec
- all_collected_paths collects clones of batches before they're sent via batch_tx (avoids ownership issues)
- POC checkpoint: 17-21% total latency improvement at 50K results, CPU ratio dropped 4-7pp
- GPU-side newline scan eliminates CPU backward/forward scan but CPU still dominates at 65-72% (string conversion + result building)
- Next optimization opportunity: reduce CPU extract overhead further (possibly batch string conversion or zero-copy results)
- find_line_bounds() takes device const uchar* — cannot reuse in content_search_kernel which uses thread-local uchar[] (different MSL address space). Would need template or second overload.
- LineBounds struct + inline function works well for MSL code reuse across kernels sharing same memory access pattern
