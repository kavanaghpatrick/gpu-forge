# Progress: gpu-search-dedup

## Overview
Spec for GPU-side lock-free hash table dedup in gpu-search-ui. Eliminates CPU bottleneck (3.6s → <1ms) by moving path deduplication to GPU after search.

## Spec Phase Status
- [x] Research: DONE — Feasibility HIGH, effort SMALL, risk LOW
- [x] Requirements: DONE — 8 FRs, 7 NFRs, 3 user stories
- [x] Design: DONE — 2-stage pipeline, FNV-1a hash, atomic CAS linear probing
- [x] Tasks: DONE — 16 tasks (POC→Refactor→Test→QA)

## Key Decisions
1. **FNV-1a over MurmurHash3**: Simpler (2 ops/byte), SIMD-friendly, <5% collision rate
2. **Keys-only hash table**: Value field unused, reduces footprint to 4B/entry (100K = 400KB)
3. **Atomic CAS with linear probing**: Proven in metal-lockfree-hashtable V3, avg 1.3 probes at 50% load
4. **Path extraction in-kernel**: Scan backward/forward for newlines (avg 131B per path)
5. **GPU-only insert, CPU filter**: Dedup happens on GPU, CPU just reads unique_flags array

## Learnings
- metal-lockfree-hashtable V3 AoS pattern already proven at 5438 Mops; can reuse atomic CAS logic
- GPU Forge finding #266: Apple GPU cache line = 128 bytes, FNV-1a fits budget (<50 ops per path)
- Path strings avg 131B on macOS; newline-bounded scanning is efficient (fits in local register pool)
- gpu-search-ui already uses `metal` crate (metal-rs), same as metal-lockfree-hashtable — no crate conflict
- Atomic CAS with relaxed ordering sufficient (GPU insert only, no inter-kernel ordering needed)
- 50% load factor standard for linear probing; 100K capacity supports 50K unique matches

## Integration Points
- **search.rs**: GpuContentSearch.new_for_paths() allocates hash_table_buffer + unique_flags_buffer; search_paths() calls dedup() after path_search
- **shader.rs**: Add dedup_kernel to PATH_SEARCH_SHADER (same library as path_search_kernel for code locality)
- **app.rs**: Replace HashSet::insert loop with unique_flags filter (1-2 lines change)

## Completed Tasks
- [x] 1.1 Add dedup_kernel MSL source to shader.rs - 21dffe1 (gpu-search-ui) + 5f4a397e9 (gpu_kernel)
- [x] 1.2 Add hash table buffer + dedup pipeline to GpuContentSearch
- [x] 1.3 Implement dedup() method to dispatch kernel
- [x] 1.4 Integrate dedup into search_paths()
- [x] 1.5 Add CPU filter in app.rs search_thread()
- [x] 1.X POC Checkpoint - verified
- [x] 2.1 Extract dedup helper function + error handling - 5c993d8 (gpu-search-ui)

## Current Task
Awaiting next task


## Learnings (Implementation)
- dedup_kernel added inside PATH_SEARCH_SHADER raw string (same Metal library as path_search_kernel)
- Hash sentinel EMPTY_KEY=0xFFFFFFFF requires guard: if hash==EMPTY_KEY, remap to 0xFFFFFFFE
- DEDUP_TABLE_CAPACITY=131072 (128K) at 50% load supports 65K unique paths
- Reused existing PathMatchResult struct and CHUNK_SIZE define from path_search_kernel
- dedup_pipeline compiled from path_library (same Metal library as path_search_kernel)
- hash_table_buffer: 131072 * 4 = 512KB, unique_flags_buffer: 100K * 1 = 100KB
- Hash table initialized to 0xFF (EMPTY_KEY sentinel) via std::ptr::write_bytes in new()
- All 13 existing search tests pass with new fields added
- dedup() uses dispatch_thread_groups (not dispatch_threads) — 1 thread per match, 256 per group
- Hash table cleared to 0xFF (EMPTY_KEY) and flags cleared to 0 before each dispatch
- Binds: chunks(0), path_matches(1), hash_table(2), match_count(3), unique_flags(4)

- dedup() called between path_search wait_until_completed and CPU extraction — reads raw_count first, then dispatches dedup
- unique_flags_buffer read as *const u8 pointer, checked per-match in extraction loop (0=skip, 1=keep)
- dedup() already clears hash_table (0xFF) and flags (0x00) internally, no extra clearing needed in search_paths()
- CPU HashSet dedup in app.rs removed — GPU dedup handles it; only multi-word filter remains on CPU
- HashSet import became unused after removal; cleaned up to avoid warnings
- **CRITICAL BUG**: dedup() received uncapped raw_count from GPU — unique_flags_buffer only MAX_MATCHES (100K) bytes but match_count could be 500K+. write_bytes overflowed → SIGSEGV. Fixed by capping to MAX_MATCHES inside dedup(). Commit c204bc0.
- Also cap GPU dispatch thread count to capped value (no point dispatching threads for matches beyond buffer)
- POC Checkpoint: 90 tests pass (52 unit x2, 6 bridge, 10 path_search, 10 engine, 2 integration), 0 failures
- Clippy clean after fixing manual div_ceil → .div_ceil() in dedup() dispatch
- App runs from / with 5M indexed paths without crashing — dedup kernel functional end-to-end

- dedup_with_error() wraps dedup() with Instant timing + overflow logging; keeps dedup() unchanged for callers
- fnv1a_hash_cpu() marked #[cfg(test)] to avoid dead_code warning; used by test_fnv1a_hash and test_dedup_collision_rate
- FNV-1a collision rate at 50% load (65536 paths, 131072 table): ~21% slot collisions from birthday paradox — expected, linear probing handles it

## Next
Task 2.2: Add hash table pre-clearing optimization
