---
spec: gpu-single-cmdbuf
basePath: specs/gpu-single-cmdbuf
phase: tasks
task: 0/13
updated: 2026-02-15T17:00:00Z
---

# Progress: gpu-single-cmdbuf

## Original Goal

Eliminate the 91 command buffers per token bottleneck in metal-attention GPU inference. Currently each layer requires 3 separate command buffers due to CPU-side KV cache memcpy (contents() pointer). Fix: (1) GPU-side kv_cache_copy Metal kernel to append K/V within compute encoder, (2) collapse all 30 layers into a single command buffer with one compute encoder per forward_token(), (3) eliminate all CPU sync points in decode hot path. Target: 300+ tok/s (from current 75 tok/s). This is the single biggest optimization — llama.cpp uses 1 command buffer per graph eval.

## Completed Tasks

- [x] 1.1 Create kv_cache_copy and buffer_copy Metal shaders - be380d2
- [x] 1.2 Add encode_kv_append to GpuKVCache - 6cc13fe
- [x] 1.3 Add encode_buffer_copy and PSO prewarm to GpuForwardPass - 7e4e0ec
- [x] 1.4 [VERIFY] Quality checkpoint: build compiles - VERIFIED
- [x] 1.5 Extract forward_token_debug and refactor forward_token to single command buffer
- [x] 1.6 [VERIFY] Correctness: all workspace tests pass - VERIFIED
- [x] 1.7 POC Checkpoint: verify tok/s improvement with benchmark
- [x] 2.1 Add unit tests for kv_cache_copy and buffer_copy kernels
- [x] 2.2 [VERIFY] Quality checkpoint: clippy + full test suite - VERIFIED
- [x] 2.3 Clean up dead code and update doc comments
- [x] 3.1 [VERIFY] Full local CI: build + clippy + test + benchmark - VERIFIED
- [x] 3.2 Create PR - Updated PR #2 (https://github.com/kavanaghpatrick/metal-attention/pull/2)

## Current Task

Awaiting next task

## Next

Task 3.3: [VERIFY] AC checklist

## Learnings

- **91 command buffers per token is the primary bottleneck**: Current architecture creates 3 cmd buffers per layer (attention proj, attention output, FFN) + 1 final = 91 total. Each commit+waitUntilCompleted incurs ~10-30us CPU overhead + GPU idle time + power cycling risk.
- **GPU Forge KB-136 confirms 6.4x regression**: Splitting 50 compute passes into 50 cmd buffers causes 641% slowdown on M1. Our 91 cmd buffers extrapolates to ~6.4x slowdown vs single buffer, directly explaining the 5.2x gap to llama.cpp (75 vs 389 tok/s).
- **Apple best practice violated by 45x**: Metal Best Practices Guide recommends 1-2 cmd buffers max per frame. Our 91 violates this by 45x.
- **GPU power cycling adds ~2.5ms overhead**: KB-1130 documents GPU sleep/wake latency when command buffers have gaps. With 91 commit+wait cycles, likely triggering power cycling on every token = ~27ms/token overhead = 37 tok/s ceiling from power cycling alone.
- **llama.cpp uses 1 command buffer per token**: ggml-metal.m creates 4-8 cmd buffers for parallel CPU encoding (across threads), but all ops for single token execute via enqueued sequential buffers. Single-threaded decode reduces to 1 cmd buffer per graph eval.
- **Metal 3 provides implicit ordering within encoder**: Sequential dispatches in single encoder have automatic write-after-read hazard tracking. No explicit barriers needed between kernel dispatches (Metal 4 makes this explicit with producer/consumer barriers).
- **CPU memcpy forces encoder breaks**: Current KV cache append uses contents() pointer on StorageModeShared buffers, requiring waitUntilCompleted() before CPU writes are visible to GPU. This breaks encoder continuity.
- **Solution: 2 trivial GPU kernels**: kv_cache_copy (10 lines MSL, <1us GPU time for 192-element copy) + buffer_copy (5 lines MSL, <1us for 576-element hidden state ping-pong). Both are simple element-wise copies with thread_position_in_grid dispatch.
- **Expected gain: 3-5x (75 → 225-375 tok/s)**: Eliminates 90 commit+wait cycles + GPU power cycling overhead + driver coalescing loss. Conservative estimate 3x, likely 4-5x. High chance of matching/exceeding 389 tok/s target.
- **Feasibility: HIGH, Risk: LOW**: Well-understood optimization, clear implementation path, Metal 3 guarantees sequential ordering, no new GPU features needed. llama.cpp/exllama/metalQwen3 all use single cmd buffer pattern.
- **Related spec: gpu-inference-pipeline already documented this**: Lines 343-363 in .progress.md explicitly call out single cmd buffer as "critical path" optimization after POC measured 75 tok/s baseline.
- **Quality commands discovered**: No Makefile/CI; use cargo directly. GPU tests require MTL_SHADER_VALIDATION=1 and --test-threads=1. Clean rebuild needs `cargo clean -p metal-attention-kernels` after adding .metal files.

- **Two CPU copy_buffer calls also need GPU migration**: `encode_attention_output` and `encode_ffn_block` both call `copy_buffer(&scratch_residual, &hidden_a, hidden_size*4)` after commit+wait. These are additional encoder breaks beyond KV cache append.
- **Debug mode needs separate strategy**: GPU_DEBUG per-layer readback requires waitUntilCompleted between layers. Recommendation: fall back to multi-cmd-buffer path when GPU_DEBUG=1 (debug perf irrelevant).
- **KV cache len tracking subtlety**: `self.len += 1` must happen on CPU after kernel dispatch but before next layer reads kv_len. Since kernel is dispatched (not yet executed), CPU increment is safe — kv_len is passed as parameter to subsequent dispatches, not read from GPU.
- **All encode_* methods already take &MTLComputeCommandEncoder**: No API changes needed for existing kernel dispatch methods. Only new methods: encode_kv_cache_copy and encode_buffer_copy.
- **PSO prewarm list must be updated**: Lines 194-207 in gpu_forward_pass.rs prewarm all kernel PSOs at model load. Two new PSOs (kv_cache_copy, buffer_copy) must be added to avoid first-dispatch compilation stall.

- **encode_kv_append belongs on GpuKVCache, not GpuForwardPass**: Encapsulates cache state (k_buf, v_buf, len, kv_dim). PSO is passed in to avoid borrow checker conflict with PsoCache owned by GpuForwardPass.
- **PSO must be pre-looked-up before calling encode_kv_append**: Can't pass &PsoCache because GpuForwardPass owns both PsoCache and GpuKVCacheSet. Look up PSO ref first, then pass to encode method.
- **dispatchThreads (not dispatchThreadgroups) is the codebase pattern**: rope_apply and residual_add both use dispatchThreads_threadsPerThreadgroup with total thread count as grid width. Metal runtime handles threadgroup sizing.
- **build.rs auto-discovers .metal files**: No need to update build.rs when adding new shaders. Just place files in shaders/ directory. Must do `cargo clean -p metal-attention-kernels` after adding new .metal files.
- **forward_token_debug must be a separate method**: Extracting current multi-cmd-buffer logic preserves debug instrumentation without polluting the optimized hot path. The debug path calls the old encode_attention_projections/encode_attention_output/encode_ffn_block methods.
- **Inlining removes 4 private methods**: encode_attention_projections, encode_attention_output, encode_ffn_block, encode_final_logits are each single-use methods that create cmd_buf+encoder. In single-cmd-buf refactor, their logic is inlined into forward_token() with shared encoder. These methods become dead code (retained only in forward_token_debug).
- **copy_buffer() free function becomes dead code**: Replaced by encode_buffer_copy() GPU kernel dispatch. Can be removed after refactor (only used in debug fallback if needed, but debug path retains its own commit+wait + CPU copy pattern).
- Task planning: 13 tasks across 3 phases (7 POC + 3 quality + 3 PR). Kept under 15 as requested.
- Task planning: build.rs auto-discovers .metal files but `cargo clean -p metal-attention-kernels` required after adding new shaders (cached build artifacts don't include them).
- Task planning: Borrow checker risk — forward_token loop needs both `&self.pso_cache` (immutable) and `&mut self.kv_caches` (mutable). Pre-lookup PSO before mutable borrow to avoid conflict.
- Task planning: 4 old private methods (encode_attention_projections, encode_attention_output, encode_ffn_block, encode_final_logits) retained for forward_token_debug. May get dead_code warnings — suppress with allow attribute or restructure debug path.
- Task planning: Test pattern for new kernels requires direct dispatch (no dispatch_ convenience function exists). Use low-level cmd_buf + encoder + set_buffer/set_bytes pattern from existing tests.
- Task planning: correctness.rs is the right place for kernel unit tests (existing pattern with gen_data, assert_allclose, GpuDevice::new).
- Task planning: gpu_correctness.rs integration tests are #[ignore] and require model file — good for final validation but not for unit testing.

- **Borrow checker: field-level disjoint borrowing works as expected**: `self.kv_caches.cache_mut(i).encode_kv_append(&encoder, kv_copy_pso, &self.scratch_k, &self.scratch_v)` compiles because Rust can see `&mut self.kv_caches` and `&self.scratch_k`/`&self.scratch_v` are disjoint field borrows. No need to destructure self or pre-borrow fields into locals.
- **NLL makes sequential encode_* calls safe**: Each `self.encode_*(...)` call borrows `&self` but the borrow is released after the call returns (NLL). So `self.encode_rmsnorm(...)` followed by `self.kv_caches.cache_mut(...)` works without conflict.
- **kv_copy_pso pre-lookup is sufficient**: Only the kv_cache_copy PSO needs pre-lookup (before the loop). All other PSOs are looked up inside encode_* methods which take `&self` — these borrows don't conflict with the later `&mut self.kv_caches` because they're sequential (NLL drops them).
- **forward_token_debug skips embed_lookup**: embed_lookup is called in forward_token before the debug branch. forward_token_debug picks up from there, avoiding double embedding lookup.

### Benchmark: 1.7 POC Checkpoint
- GPU correctness tests: 2/2 PASS (test_gpu_vs_cpu_greedy_match, test_gpu_vs_cpu_logits)
- **Benchmark result: 257-262 tok/s** (avg across multiple runs)
  - Run 1: 257.0 tok/s (0.3890s avg, 3 iterations)
  - Run 2: 261.9 tok/s (0.3819s avg, 3 iterations)
- **Improvement: 3.43-3.49x over 75 tok/s baseline** (91 cmd buffers -> 1 cmd buffer)
- **vs targets**:
  - 75 tok/s baseline: **3.43x improvement** (PASS - measurable improvement)
  - 300 tok/s target: 86% of target (not yet reached)
  - 389 tok/s llama.cpp: 66% of llama.cpp
- **Analysis**: Single command buffer eliminates ~90 commit+waitUntilCompleted cycles (~1.3ms overhead per token eliminated). Remaining gap to 300+ likely from: (1) waitUntilCompleted still used for final readback (vs async completion handlers), (2) no kernel fusion (30 individual rmsnorm+matvec dispatches vs fused), (3) StorageModeShared bandwidth (vs Managed with explicit sync). These are follow-on optimizations.
- **POC success**: 3.4x improvement confirms the hypothesis that command buffer overhead was the primary bottleneck. The single command buffer architecture is correct and working.

### Verification: 1.6 [VERIFY] Correctness: all workspace tests pass
- Status: PASS
- Commands:
  - `MTL_SHADER_VALIDATION=1 cargo test --workspace -- --test-threads=1` (exit 0)
    - 37 metal-attention unit tests: PASS
    - 7 sampling property tests: PASS
    - 15 e2e tests: PASS
    - 13 model_load tests: PASS
    - 49 gguf unit tests: PASS
    - 65 kernels unit tests: PASS
    - 36 correctness tests: PASS
    - 10 property tests: PASS
    - 48 models unit tests: PASS
    - 14 traits unit tests: PASS
    - Total: 294 passed, 0 failed, 4 ignored
  - `MTL_SHADER_VALIDATION=1 cargo test -p metal-attention --test gpu_correctness -- --ignored --test-threads=1` (exit 0)
    - test_gpu_vs_cpu_greedy_match: PASS
    - test_gpu_vs_cpu_logits: PASS
    - Both tests ran with real GGUF model file, completed in 18.2s
- Metal GPU Validation: Enabled, no validation errors
- No fixes needed — single command buffer refactor passes all tests on first attempt

### Verification: 1.4 [VERIFY] Quality checkpoint: build compiles
- Status: PASS
- Command: `cargo build --workspace` (exit 0)
- Warnings: 1 (dead_code: `encode_buffer_copy` in gpu_forward_pass.rs:858 — expected, will be used in task 1.5)
- Errors: 0
- Metal shaders compiled successfully: shaders.metallib includes kv_cache_copy and buffer_copy
- No fixes needed

## Blockers

- None currently

- **POC benchmark: 257-262 tok/s (3.4x improvement)**: Single command buffer refactor yields 3.4x speedup from 75 tok/s baseline. Below the 300+ target but confirms cmd buffer overhead was the primary bottleneck. Remaining gap attributable to: final waitUntilCompleted, no kernel fusion, StorageModeShared bandwidth.
- **cargo clean required for release metallib too**: `cargo clean -p metal-attention-kernels` only cleans debug; must use `cargo clean` (full) to rebuild release metallib with new shaders. Otherwise get "Function kv_cache_copy was not found" at runtime.
- build.rs successfully auto-discovered new .metal files after cargo clean -p metal-attention-kernels; shaders.metallib rebuilt with kv_cache_copy and buffer_copy included
- metal-attention/ is a separate git repo (branch feat/gguf-weight-loading), not a submodule of gpu_kernel. Code changes must be committed in the metal-attention repo directly (cd metal-attention && git add/commit). Parent gpu_kernel repo only tracks spec files under specs/.
- **Low-level Metal dispatch in tests requires 5 trait imports**: MTLBuffer, MTLCommandBuffer, MTLCommandEncoder, MTLCommandQueue, MTLComputeCommandEncoder from objc2_metal. Without these in scope, methods like commandBuffer(), computeCommandEncoder(), endEncoding(), commit(), waitUntilCompleted(), and contents() are not found. The `--test correctness` target also requires `-p metal-attention-kernels` since it's a workspace.
- **Clippy verify command false positive**: `cargo clippy --workspace 2>&1 | grep -c "warning"` counts build.rs output lines like "warning: metal-attention-kernels@0.1.0: Built shaders.metallib" which are not clippy diagnostics. Use `grep "^warning\["` to count only actual clippy warnings.
- **No dead code warnings from single-cmdbuf refactor**: The 4 old methods (encode_attention_projections, encode_attention_output, encode_ffn_block, encode_final_logits) and copy_buffer are still used by forward_token_debug, so no dead_code warnings arise.

### Verification: 2.2 [VERIFY] Quality checkpoint: clippy + full test suite
- Status: PASS
- Commands:
  - `cargo clippy --workspace --all-targets` (exit 0)
    - Warnings: 23 total, all pre-existing in untouched files (matvec_q4_0.rs, paged.rs, residual.rs, decode_attention.rs, norm.rs, property.rs, correctness.rs, tokenizer.rs)
    - Warning types: needless_range_loop, manual_div_ceil, useless_vec, assertions_on_constants, manual_is_multiple_of
    - Zero new warnings from gpu-single-cmdbuf changes
    - Zero errors
  - `MTL_SHADER_VALIDATION=1 cargo test --workspace -- --test-threads=1` (exit 0)
    - metal-attention: 37 passed
    - sampling_property: 7 passed
    - e2e: 15 passed
    - model_load: 13 passed
    - metal-attention-gguf: 49 passed
    - metal-attention-kernels: 65 passed
    - correctness: 39 passed (includes test_kv_cache_copy_gpu_vs_cpu, test_buffer_copy_gpu_vs_cpu, test_buffer_copy_small)
    - property: 10 passed
    - metal-attention-models: 48 passed
    - metal-attention-traits: 14 passed
    - Total: 297 passed, 0 failed, 4 ignored
  - Metal GPU Validation: Enabled, no validation errors
- Test Quality Check: PASS (all new tests use real GPU device, real kernel dispatch, real buffer readback, zero mocks)
- No fixes needed

### Verification: 3.1 [VERIFY] Full local CI: build + clippy + test + benchmark
- Status: PASS
- Commands:
  - `cargo build --workspace` (exit 0)
    - Zero errors, metallib built successfully
  - `cargo clippy --workspace` (exit 0)
    - Zero clippy diagnostic warnings (build.rs info line only)
  - `MTL_SHADER_VALIDATION=1 cargo test --workspace -- --test-threads=1` (exit 0)
    - metal-attention: 37 passed
    - sampling_property: 7 passed
    - e2e: 15 passed
    - model_load: 13 passed
    - metal-attention-gguf: 49 passed
    - metal-attention-kernels: 65 passed
    - correctness: 39 passed
    - property: 10 passed
    - metal-attention-models: 48 passed
    - metal-attention-traits: 14 passed
    - Total: 297 passed, 0 failed, 4 ignored
  - `cargo test -p metal-attention --test gpu_correctness -- --ignored --test-threads=1` (exit 0)
    - test_gpu_vs_cpu_greedy_match: PASS
    - test_gpu_vs_cpu_logits: PASS
    - 2/2 GPU correctness tests passed (18.3s)
  - `cargo run --release -- bench --gpu -m models/SmolLM-135M.Q4_0.gguf --gen-length 100 --iterations 3 --seq-lengths 3` (exit 0)
    - **Benchmark: 257.2 tok/s** (0.3888s avg, 3 iterations, seq_len=3)
    - 3.43x improvement over 75 tok/s baseline
    - 86% of 300 tok/s target
- No fixes needed
