---
spec: gpu-kernel-rewrites
basePath: ./specs/gpu-kernel-rewrites
phase: requirements
task: 0/0
updated: 2026-02-17
---

# Progress: gpu-kernel-rewrites

## Original Goal

Rewrite ALL 15 GPU compute experiment kernels (reduce, histogram, GEMM, GEMV, spreadsheet, scan, sort, compact, filter, groupby, pipeline, timeseries, hash_join, json_parse, duckdb) to best-in-class Apple Silicon implementations using KB-verified best practices. Include cross-cutting fixes like GPU-side timing (GPUStartTime/GPUEndTime), vectorized loads, simdgroup_matrix, coalesced memory access, multi-element-per-thread, single command buffers, buffer storage mode optimization, and PSO occupancy hints. Target 5-15x GPU speedups at 10M elements across the board.

## Completed Tasks

- [x] 1.1 Add GpuTimer to timing.rs and export from lib.rs
- [x] 1.2 Upgrade PsoCache to descriptor-based PSO with occupancy hints
- [x] 1.3 Add vectorized load helpers to types.h
- [x] 1.4 [VERIFY] Quality checkpoint: cargo build + cargo test
- [x] 1.5 Rewrite reduce.metal with two-pass atomic-free kernel
- [x] 1.6 Update reduce.rs to use two-pass dispatch + GpuTimer
- [x] 1.7 Rewrite scan.metal with SIMD prefix scan

## Current Task

Awaiting next task

## Learnings

- **GPUStartTime/GPUEndTime confirmed available** in objc2-metal 0.2.2 (MTLCommandBuffer.rs:240-244). Replaces Instant::now() wall-clock timing (includes ~300us firmware overhead per dispatch).
- **Radix sort scatter quadratic cost verified**: Loop at lines 134-138 compares digit against up to 256 previous threads (32,768 total comparisons per TG). Fix: simd_prefix_exclusive_sum().
- **Histogram modulo operation verified**: Line 52 uses `%` instead of `&` bitmask. Power-of-2 bins enable bitmask optimization.
- **Spreadsheet row-major strided access verified**: Line 38 accesses grid[row * cols + col], causing 32x cache waste on column-sum task. Requires dispatch rewrite.
- **Command buffer patterns confirmed**: sort.rs, compact.rs, duckdb.rs show multiple commit()+waitUntilCompleted() calls (8, 3, 10+ respectively). Single-cmdbuf pattern with multiple encoders will eliminate 400-1600us overhead.
- **PSO cache missing occupancy hints**: pso_cache.rs line 71 uses newComputePipelineStateWithFunction_error() with default descriptor. Needs MTLComputePipelineDescriptor with maxTotalThreadsPerThreadgroup=256.
- **Scan Blelloch 18-barrier cost verified**: Up-sweep (9) + down-sweep (9) = 18 global synchronization points. simd_prefix_exclusive_sum() reduces to 2 barriers (available MSL 4.0, A14+).
- **GEMM lacks simdgroup_matrix**: Current 16x16 tiled GEMM uses single-element-per-thread. simdgroup_matrix_multiply_accumulate() delivers 37% improvement (80% ALU util vs 25%).
- **No existing quality commands**: Project uses standard Cargo (cargo build/test/check/fmt). No Makefile, no CI configs, no package.json scripts found.
- **GPUStartTime/GPUEndTime require `objc2-core-foundation` feature** on objc2-metal, but it IS in the default features of 0.3.2, so no Cargo.toml changes needed. Return type is `CFTimeInterval` (f64) in seconds.
- **Reduce f32 atomic CAS cap of 64 iterations**: line 119, silent data loss beyond 64 concurrent updates. Two-pass atomic-free pattern eliminates this bottleneck.

## Interview Responses

### Requirements Interview (from requirements.md)
- Primary users: Internal developers only
- Priority tradeoffs: Prioritize performance correctness â€” every kernel must hit its target speedup with verified benchmarks
- Success criteria: All 15 kernels beat CPU at 10M elements (GPU > 1.0x for every experiment at scale)

## Learnings (Requirements Phase)

- **Experiment trait interface is stable**: `run_gpu() -> f64` returns wall-clock ms; GPU timing change means replacing `BenchTimer::start/stop` with `GPUStartTime/GPUEndTime` inside each experiment's `run_gpu()`, not changing the trait signature.
- **PsoCache compile_pso uses simplest API**: `newComputePipelineStateWithFunction_error()` at line 71; switching to descriptor-based requires `MTLComputePipelineDescriptor` import and 4-line change.
- **alloc_buffer always StorageModeShared**: dispatch.rs line 121 hardcodes `MTLResourceOptions::StorageModeShared` for all buffers. StorageModePrivate deferred (needs blit copy infrastructure).
- **Benchmark profiles already support 10M**: standard_profile() includes `[1_000_000, 10_000_000]` with 10 runs and 3 warmup -- matches our methodology exactly.
- **IQR outlier removal already implemented**: stats.rs `compute_stats()` uses Q1-1.5*IQR / Q3+1.5*IQR filtering, so benchmark stability is handled.
- **GEMV uses matrix dimension as "size" not element count**: GEMV at 768 means 768x768 matrix (590K elements). 4096 = 16.7M elements -- large enough for GPU to win.
- **Hash Join at 167x needs no changes**: Requirements explicitly exclude it from optimization work.
- **Composite kernels (compact, groupby, pipeline, duckdb) don't need individual shader rewrites**: They call sort/scan/filter as components, so improvements cascade automatically.
- **Speedup targets set conservatively**: Minimum targets (5x reduce, 3x histogram, etc.) are below research estimates (5-10x, 5-15x) to account for real-world variance.

### Design Interview (from design.md)
- Architecture style: Extend existing architecture (modify forge-primitives shaders + dispatch, forge-bench experiments)
- Technology constraints: No constraints beyond Metal 3 / MSL 3.1+ / objc2-metal 0.3.2
- Integration approach: Use existing APIs and interfaces (Experiment trait, PsoCache, dispatch helpers)

## Learnings (Design Phase)

- **objc2-metal 0.3.2 GPUStartTime/GPUEndTime require `objc2-core-foundation` feature**: Confirmed available in default features. API is `fn GPUStartTime(&self) -> CFTimeInterval` on MTLCommandBuffer trait. Safe to call after commit+waitUntilCompleted.
- **PSO descriptor API**: `newComputePipelineStateWithDescriptor_options_reflection_error()` requires features `MTLAllocation`, `MTLComputePipeline`, `MTLLibrary` -- all in default features. Descriptor class is `MTLComputePipelineDescriptor::new()`.
- **Setter for threadGroupSizeIsMultipleOfThreadExecutionWidth is `unsafe`** in objc2-metal 0.3.2, needs unsafe block.
- **compact.rs already uses single command buffer** for <= MAX_GPU_PARTIALS (512). Only CPU fallback path creates a second cmd_buf. At 10M elements with 512 elements/TG = 19532 scan TGs, which exceeds 512 -- **needs 3-level scan or larger partials capacity**.
- **sort.rs per-pass creates command buffer + allocates SortParams**: Hot loop allocates via `alloc_buffer_with_data` per pass. Pre-allocating 8 SortParams buffers in setup() eliminates this.
- **Histogram zeroing for sort**: CPU loop `ptr.add(i) = 0` can be replaced with `blitCommandEncoder().fillBuffer_range_value()` to keep everything on GPU.
- **Scan elements per TG increase from 512 to 1024**: With 4 elements/thread (uint4 loads), each TG processes 1024 elements. This changes partials count: at 10M, need ceil(10M/1024) = 9766 partials. Exceeds 512 capacity of scan_partials. **Must implement multi-level scan** (9766 -> 10 -> 1).
- **GEMM simdgroup_matrix dispatch**: With 16x16 TG (256 threads = 8 SIMD groups), each SIMD group computes one 8x8 output tile. Four SIMD groups cover the 16x16 output in a 2x2 arrangement. Shared memory needs +4 padding per row for bank conflict avoidance.
- **Spreadsheet underutilization is primary bottleneck**: At 10M cells (3162x3162), current dispatch creates only 13 TGs (ceil(3162/256)). Fix: 2D dispatch with row chunking gives 9900 TGs.
- **No generic multi-pass dispatch helper warranted**: Sort (ping-pong), compact (sequential), spreadsheet (independent) have too-different patterns for a shared abstraction. Per-experiment refactor is cleaner.
- **build.rs auto-discovers .metal files**: No changes needed for new kernel functions within existing .metal files. Only new .metal files need cargo rerun-if-changed. Adding functions to existing files (reduce_sum_u32_v2 to reduce.metal) works automatically.
- **types.h is the only shared header tracked in build.rs**: Adding vec helpers to types.h triggers recompile of all shaders via `cargo:rerun-if-changed=shaders/types.h`.
- **u32 reduce overflows at 10M**: With random u32 data, sum exceeds u32::MAX. Validation must compare as u32 (wrapping) since GPU operates in u32. Modular arithmetic is associative/commutative, so GPU and CPU wrapping results match regardless of evaluation order.
- **PsoCache borrow checker**: Cannot hold two `&ProtocolObject<dyn MTLComputePipelineState>` references from `get_or_create()` simultaneously (both borrow `&mut self.pso_cache`). Fix: scope each PSO lookup to its encoder block.
- **3-level reduce needed at 10M**: 10M elements / 1024 elements/TG = 9766 partials. Exceeds single-TG capacity (1024). Chain: 9766 -> 10 -> 1 via v2 + v2 + partials kernels.

### Tasks Interview (from tasks.md)
- Testing depth: Standard - unit + integration (per-kernel correctness + benchmark validation)
- Deployment approach: Standard CI/CD pipeline (cargo build/test/bench)
- Execution priority: Balanced - reasonable quality with speed
- Additional execution context: User wants continuous progress without stopping for questions

## Learnings (Task Planning Phase)

- **96 tests currently pass** (65 forge-bench + 31 forge-primitives). This is the regression baseline.
- **objc2-metal version is 0.3** (not 0.2.2 as earlier noted). GPUStartTime/GPUEndTime available in 0.3.
- **Scan rewrite changes partials capacity**: increasing ELEMENTS_PER_TG from 512 to 1024 means 10M elements produce 9766 partials. scan_partials with 4 elem/thread handles 1024 partials max (256 threads * 4). For 9766: need multi-level scan (9766 -> 10 -> 1). sort.rs histogram scan also affected.
- **sort.rs creates cmd_buf PER PASS in the 8-pass loop**: lines 228-231 create new cmd_buf each iteration. Single-cmdbuf refactor moves creation BEFORE the loop.
- **sort.rs CPU histogram zeroing in hot loop**: lines 202-207 use `ptr.add(i) = 0` for histogram_size elements. Must replace with blitCommandEncoder for single-cmdbuf pattern.
- **compact.rs needs ELEMENTS_PER_TG update to 1024**: currently uses 512, must match scan rewrite.
- **dispatch_1d helper uses `pipeline.maxTotalThreadsPerThreadgroup().min(256)`**: PSO occupancy hints may change maxTotalThreadsPerThreadgroup, affecting dispatch_1d behavior. After PSO hint change, verify dispatch_1d still produces correct TG size.
- **PSO descriptor API confirmed working**: `MTLPipelineOption::None` (bitflags syntax), `setThreadGroupSizeIsMultipleOfThreadExecutionWidth` is `unsafe`, reflection param accepts `None`. All 96 tests pass with descriptor-based PSO creation. `MTLDevice` import not needed (already available via `library.device()`).
- **Task ordering is critical**: GpuTimer (1.1) must precede all experiments. types.h (1.3) must precede shader rewrites. scan.metal (1.7) must precede sort.rs (2.2) since sort uses scan kernels. All rewrites must precede composite validation (3.1).
- **38 tasks total across 5 phases**: Phase 1 (11 POC), Phase 2 (12 feature), Phase 3 (3 testing), Phase 4 (2 quality), Phase 5 (3 PR lifecycle).
- **NUM_BINS is always 256** in histogram.rs (const `NUM_BINS: u32 = 256`). Power-of-2 guaranteed for this experiment. Bitmask safe.
- **SIMD prefix scan pattern**: simd_prefix_exclusive_sum for intra-SIMD, threadgroup uint simd_totals[8] for cross-SIMD aggregation. Only 3 barriers total (down from 18 Blelloch). Last thread (255) computes TG total as base_offset + thread_total via shared memory.

## Blockers

- None currently

### Verification: 1.4 [VERIFY] Quality checkpoint: cargo build + cargo test
- Status: PASS
- Commands: cargo build --release (exit 0), cargo test --release (exit 0)
- Build: Succeeded with 8 pre-existing dead code warnings (zero new warnings from tasks 1.1-1.3)
- Tests: 96 passed (65 forge-bench + 31 forge-primitives), 0 failed, 0 ignored
- Pre-existing warnings: zero_histogram_buffer (sort.rs), update (progress.rs), description/supported_sizes (mod.rs), par_sum_f32/par_min_u32/par_max_u32/par_sort_u32/sequential_histogram (cpu_baselines) -- all dead code, none introduced by infrastructure changes
- No fixes needed

## Next

Task 1.8: Update scan.rs for new dispatch grid + GpuTimer
